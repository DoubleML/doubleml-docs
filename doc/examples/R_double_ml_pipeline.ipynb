{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126e2f75",
   "metadata": {},
   "source": [
    "# R: Ensemble Learners and More with `mlr3pipelines`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30571a",
   "metadata": {},
   "source": [
    "This notebook illustrates how to exploit the powerful tools provided by the [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) package (Binder et al. 2021). For example, [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) can be used in combination with [DoubleML](https://docs.doubleml.org/stable/index.html) for feature engineering, combination of learners (ensemble learners, stacking), subsampling and hyperparameter tuning. The underlying idea of [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) is to define a pipeline that incorporates a user's desired operations. As a result, the pipeline returns an object of class [Learner](https://mlr3.mlr-org.com/reference/Learner.html) which can easily be passed to [DoubleML](https://docs.doubleml.org/stable/index.html). For an introduction to [mlr3pipelines](https://mlr3pipelines.mlr-org.com/), we refer to the [Pipelines Chapter](https://mlr3book.mlr-org.com/pipelines.html) in the [mlr3book](https://mlr3book.mlr-org.com) (Becker et al. 2020) and to the [package website](https://mlr3pipelines.mlr-org.com/).\n",
    "\n",
    "\n",
    "We intend to illustrate the major idea of how to use [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) in combination with [DoubleML](https://docs.doubleml.org/stable/index.html) in very simple examples. We use pipelines that are identical or very similar to the ones in the [Pipelines Chapter](https://mlr3book.mlr-org.com/pipelines.html) in the [mlr3book](https://mlr3book.mlr-org.com). Hence, we do not claim that the proposed learners are optimal in terms of their performance.\n",
    "\n",
    "We start with the simple simulated data example and the [Bonus data set](https://docs.doubleml.org/r/stable/reference/fetch_bonus.html) from the [Getting Started Section in the DoubleML user guide](https://docs.doubleml.org/dev/intro/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc314dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(DoubleML)\n",
    "\n",
    "# Simulate data\n",
    "set.seed(3141)\n",
    "n_obs = 500\n",
    "n_vars = 100\n",
    "theta = 3\n",
    "X = matrix(rnorm(n_obs*n_vars), nrow=n_obs, ncol=n_vars)\n",
    "d = X[,1:3]%*%c(5,5,5) + rnorm(n_obs)\n",
    "y = theta*d + X[, 1:3]%*%c(5,5,5) + rnorm(n_obs)\n",
    "\n",
    "\n",
    "# Specify the data and variables for the causal model\n",
    "# matrix interface to DoubleMLData\n",
    "dml_data_sim = double_ml_data_from_matrix(X=X, y=y, d=d)\n",
    "dml_data_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913f88c",
   "metadata": {},
   "source": [
    "To have an example with a classification learner, we load the [Bonus data set](https://docs.doubleml.org/r/stable/reference/fetch_bonus.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bonus data\n",
    "df_bonus = fetch_bonus(return_type=\"data.table\")\n",
    "head(df_bonus)\n",
    "\n",
    "# Specify the data and variables for the causal model\n",
    "x_vars = c(\"female\", \"black\", \"othrace\", \"dep1\", \"dep2\",\n",
    "           \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"agelt35\", \"agegt54\",\n",
    "           \"durable\", \"lusd\", \"husd\")\n",
    "dim_x = length(x_vars)\n",
    "dml_data_bonus = DoubleMLData$new(df_bonus,\n",
    "                             y_col = \"inuidur1\",\n",
    "                             d_cols = \"tg\",\n",
    "                             x_cols = x_vars)\n",
    "print(dml_data_bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd66c6",
   "metadata": {},
   "source": [
    "To specify a learner for the nuisance part in a causal model, we can either use [mlr3](https://mlr3.mlr-org.com/)'s [LearnerRegr](https://mlr3.mlr-org.com/reference/LearnerRegr.html) for a model's nuisance part with a continuous dependent variable or a [LearnerClassif](https://mlr3.mlr-org.com/reference/LearnerClassif.html) if the corresponding outcome variable is binary. \n",
    "\n",
    "Moreover, it's possible to create a learner based on a pipeline. For example, we could think of [ensemble learners](https://mlr3book.mlr-org.com/pipelines.html#pipe-model-ensembles) which combine several estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23aab7",
   "metadata": {},
   "source": [
    "## Using learners from `mlr3`, `mlr3learners` and `mlr3extralearners`\n",
    "\n",
    "Let's begin with a \"standard\" example on how to use any of the learners provided by [mlr3](https://mlr3.mlr-org.com/) (Lang et al. 2020), [mlr3learners](https://mlr-org.com/learners.html) (Lang et al. 2021) and [mlr3extralearners](https://mlr3extralearners.mlr-org.com/) (Sonabend and Schratz 2021) in [DoubleML](https://docs.doubleml.org/stable/index.html): We create an object of the class [Learner](https://mlr3.mlr-org.com/reference/Learner.html) which [DoubleML](https://docs.doubleml.org/stable/index.html) internally uses for model training and generation of predictions.\n",
    "\n",
    "In the simulated example, we will use a lasso estimator for the continuous treatment variable, which is based on the [glmnet package](https://glmnet.stanford.edu/index.html).  For the binary treatment variable in the Bonus data example, we use a random forest classifier as provided by [ranger](https://github.com/imbs-hl/ranger)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0260edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(mlr3)\n",
    "library(mlr3learners)\n",
    "\n",
    "# suppress messages during fitting\n",
    "lgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n",
    "\n",
    "learner_lasso = lrn(\"regr.cv_glmnet\", s=\"lambda.min\")\n",
    "ml_l_lasso = learner_lasso$clone()\n",
    "ml_m_lasso = learner_lasso$clone()\n",
    "class(ml_l_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest learner for nuisance part ml_l\n",
    "learner_forest_regr = lrn(\"regr.ranger\",\n",
    "                          num.trees=500, mtry=floor(sqrt(dim_x)),\n",
    "                          max.depth=5, min.node.size=2)\n",
    "\n",
    "# Random forest learner for nuisance part ml_m (binary outcome)\n",
    "learner_forest_classif = lrn(\"classif.ranger\",\n",
    "                             num.trees=500,\n",
    "                             mtry=floor(sqrt(dim_x)),\n",
    "                             max.depth=5, min.node.size=2)\n",
    "\n",
    "ml_l_forest = learner_forest_regr$clone()\n",
    "ml_m_forest = learner_forest_classif$clone()\n",
    "class(ml_l_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28795baa",
   "metadata": {},
   "source": [
    "We set up a causal model, here we specify a partially linear model and thereby pass the learner as an input. Let's fit the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a231d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_sim = DoubleMLPLR$new(dml_data_sim,\n",
    "                                  ml_l=ml_l_lasso,\n",
    "                                  ml_m=ml_m_lasso)\n",
    "obj_dml_plr_sim$fit()\n",
    "print(obj_dml_plr_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_bonus = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                    ml_l=ml_l_forest,\n",
    "                                    ml_m=ml_m_forest)\n",
    "obj_dml_plr_bonus$fit()\n",
    "print(obj_dml_plr_bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0184d",
   "metadata": {},
   "source": [
    "## Set up learners based on `mlr3pipelines`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bbf84",
   "metadata": {},
   "source": [
    "These learners can also be constructed using [mlr3pipelines](https://mlr3pipelines.mlr-org.com/). We'll first use the PipeOp constructor [po()](https://mlr3pipelines.mlr-org.com/reference/po.html) to define the learner construction and then initiate a new instance of the [Learner](https://mlr3.mlr-org.com/reference/Learner.html) class. [po()](https://mlr3pipelines.mlr-org.com/reference/po.html) implements a computational step in a pipeline. For more information, we refer to the [Pipelines Chapter in the mlr3book](https://mlr3book.mlr-org.com/pipelines.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso learner\n",
    "library(mlr3pipelines)\n",
    "pipe_lasso = po(lrn(\"regr.cv_glmnet\"), s = \"lambda.min\")\n",
    "ml_l_lasso_pipe = as_learner(pipe_lasso)\n",
    "ml_m_lasso_pipe = as_learner(pipe_lasso)\n",
    "\n",
    "# Class of the lasso learner\n",
    "class(ml_l_lasso_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e41460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest learner for nuisance part ml_l\n",
    "pipe_forest_regr = po(lrn(\"regr.ranger\"),\n",
    "                      num.trees=500, mtry=floor(sqrt(dim_x)),\n",
    "                      max.depth=5, min.node.size=2)\n",
    "\n",
    "# Random forest learner for nuisance part ml_m (binary outcome)\n",
    "pipe_forest_classif = po(lrn(\"classif.ranger\"),\n",
    "                             num.trees=500,\n",
    "                             mtry=floor(sqrt(dim_x)),\n",
    "                             max.depth=5, min.node.size=2)\n",
    "\n",
    "ml_l_forest_pipe = as_learner(pipe_forest_regr)\n",
    "ml_m_forest_pipe = as_learner(pipe_forest_classif)\n",
    "\n",
    "# Class of the random forest learners\n",
    "class(ml_l_forest_pipe)\n",
    "class(ml_m_forest_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6bfb6",
   "metadata": {},
   "source": [
    "Let's use these learners to fit the PLR in both examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf86234",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_sim_pipe = DoubleMLPLR$new(dml_data_sim,\n",
    "                                       ml_l=ml_l_lasso_pipe,\n",
    "                                       ml_m=ml_m_lasso_pipe)\n",
    "obj_dml_plr_sim_pipe$fit()\n",
    "print(obj_dml_plr_sim_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9decfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_bonus_pipe = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                    ml_l=ml_l_forest_pipe,\n",
    "                                    ml_m=ml_m_forest_pipe)\n",
    "obj_dml_plr_bonus_pipe$fit()\n",
    "print(obj_dml_plr_bonus_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952de1c7",
   "metadata": {},
   "source": [
    "## Use ensemble learners based on `mlr3pipelines`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad79d6",
   "metadata": {},
   "source": [
    "First, let's see how we can use more complicated [GraphLearner](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html)s like ensemble learners in [DoubleML](https://docs.doubleml.org/). For example, we want to create a learner with predictions that are generated as an average from three different learners. In the first step, we split up the pipeline into three branches. In our example, the learners estimate the nuisance parts independently of each other. In the last step, we average the predictions. Thereby we will use the pipe operator `%>>%`. For more details, we refer to the [Pipelines Chapter in the mlr3book](https://mlr3book.mlr-org.com/pipelines.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression (nuisance parts with continuous outcome)\n",
    "graph_ensemble_regr = gunion(list(\n",
    "    po(\"learner\", lrn(\"regr.cv_glmnet\", s = \"lambda.min\")),\n",
    "    po(\"learner\", lrn(\"regr.ranger\")),\n",
    "    po(\"learner\", lrn(\"regr.rpart\", cp = 0.01))\n",
    "  )) %>>%\n",
    "    po(\"regravg\", 3)\n",
    "\n",
    "# Class of ' graph_ensemble_regr'\n",
    "class(graph_ensemble_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931817d",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "graph_ensemble_regr$plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification (nuisance part ml_m in the Bonus example)\n",
    "graph_ensemble_classif = gunion(list(\n",
    "    po(\"learner\", lrn(\"classif.cv_glmnet\", s = \"lambda.min\")),\n",
    "    po(\"learner\", lrn(\"classif.ranger\")),\n",
    "    po(\"learner\", lrn(\"classif.rpart\", cp = 0.01))\n",
    "  )) %>>%\n",
    "    po(\"classifavg\", 3)\n",
    "\n",
    "# Class of 'graph_ensemble_classif'\n",
    "class(graph_ensemble_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "graph_ensemble_classif$plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7308a1",
   "metadata": {},
   "source": [
    "We create a new instance of a [GraphLearner](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) which is later used in [DoubleML](https://docs.doubleml.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ae052",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pipe_regr = as_learner(graph_ensemble_regr)\n",
    "ensemble_pipe_classif = as_learner(graph_ensemble_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32724fc8",
   "metadata": {},
   "source": [
    "Let's estimate the two PLR examples with the ensemble learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdd413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate new DoubleML object and estimate with graph learner\n",
    "set.seed(123)\n",
    "obj_dml_plr_sim_pipe_ensemble = DoubleMLPLR$new(dml_data_sim,\n",
    "                                                ml_l = ensemble_pipe_regr,\n",
    "                                                ml_m = ensemble_pipe_regr)\n",
    "obj_dml_plr_sim_pipe_ensemble$fit()\n",
    "print(obj_dml_plr_sim_pipe_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876aee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_bonus_pipe_ensemble = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                    ml_l = ensemble_pipe_regr,\n",
    "                                    ml_m = ensemble_pipe_classif)\n",
    "obj_dml_plr_bonus_pipe_ensemble$fit()\n",
    "print(obj_dml_plr_bonus_pipe_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddb48a",
   "metadata": {},
   "source": [
    "Alternatively, different learners could also be stacked. Here we simply repeat the example from the [Pipelines Chapter in the mlr3book](https://mlr3book.mlr-org.com/pipelines.html#pipe-model-ensembles-stacking) in our Bonus data example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = lrn(\"classif.rpart\")\n",
    "lrn_0 = po(\"learner_cv\", lrn$clone())\n",
    "lrn_0$id = \"rpart_cv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass original features to final estimation step\n",
    "level_0 = gunion(list(lrn_0, po(\"nop\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99422ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = level_0 %>>% po(\"featureunion\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7357b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = combined %>>% po(\"learner\", lrn$clone())\n",
    "stack$plot(html = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d13d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stacked learner and pass it to a DoubleML object\n",
    "stacklrn = as_learner(stack)\n",
    "\n",
    "set.seed(123)\n",
    "obj_dml_plr_bonus_pipe = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                         ml_l=ml_l_forest,\n",
    "                                         ml_m=stacklrn)\n",
    "obj_dml_plr_bonus_pipe$fit()\n",
    "print(obj_dml_plr_bonus_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99764a",
   "metadata": {},
   "source": [
    "## How to exploit more features of `mlr3pipelines` in `DoubleML`\n",
    "\n",
    "[mlr3pipelines](https://mlr3pipelines.mlr-org.com/reference/Graph.html) can do much more. For example, we could use it to perform some [feature engineering](https://mlr3book.mlr-org.com/pipelines.html#pipe-modeling) and even perform pipeline-based [parameter tuning](https://mlr3book.mlr-org.com/pipelines.html#pipe-tuning). We just have to define the steps we want to have in our pipeline by using the PipeOps.\n",
    "\n",
    "Let's have a look at two more examples from the [Pipelines Chapter in the mlr3book](https://mlr3book.mlr-org.com/pipelines.html). In the first one, we will do some data manipulation. The second example illustrate how we could use [mlr3pipelines](https://mlr3pipelines.mlr-org.com/reference/Graph.html) for parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a53d1",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Let's perform some data preprocessing and then use a regression tree for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f425d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate = po(\"mutate\")\n",
    "filter = po(\"filter\",\n",
    "    filter = mlr3filters::flt(\"variance\"),\n",
    "    param_vals = list(filter.frac = 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a162782",
   "metadata": {},
   "source": [
    "Collect them in a graph and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = mutate %>>%\n",
    "  filter %>>%\n",
    "  po(\"learner\",\n",
    "    learner = lrn(\"classif.rpart\"))\n",
    "\n",
    "class(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph$plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11860a7e",
   "metadata": {},
   "source": [
    "Create a new learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e449f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "glrn = as_learner(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909193b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "glrn\n",
    "class(glrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a281d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_bonus_pipe2 = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                          ml_l=ml_l_lasso,\n",
    "                                          ml_m=glrn)\n",
    "obj_dml_plr_bonus_pipe2$fit()\n",
    "print(obj_dml_plr_bonus_pipe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d552c2f",
   "metadata": {},
   "source": [
    "Let's see how to set hyperparameters with a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27513f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glrn$param_set$values$variance.filter.frac = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "obj_dml_plr_bonus_pipe3 = DoubleMLPLR$new(dml_data_bonus,\n",
    "                                          ml_l=ml_l_lasso,\n",
    "                                          ml_m=glrn)\n",
    "obj_dml_plr_bonus_pipe3$fit()\n",
    "print(obj_dml_plr_bonus_pipe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90db3e",
   "metadata": {},
   "source": [
    "### Parameter tuning\n",
    "\n",
    "Next, we will shortly illustrate how to perform parameter tuning in the simulated data example. Here, we use a pipeline to tune the penalty of the lasso. To do so, we generate a [GraphLearner](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) and then call [DoubleML](https://docs.doubleml.org)'s [tune()](https://docs.doubleml.org/r/stable/reference/DoubleML.html#method-tune-) method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf206d",
   "metadata": {},
   "source": [
    "Let's define a [GraphLearner](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) based on the lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935daf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pipe = mutate %>>%\n",
    "  filter %>>%\n",
    "  po(\"learner\",\n",
    "    learner = lrn(\"regr.glmnet\"))\n",
    "glrn_lasso = as_learner(lasso_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4690daa8",
   "metadata": {},
   "source": [
    "Let's specify the parameter grid and more settings that are required for the parameter tuning. For more details, we refer to [the DoubleML user guide](https://docs.doubleml.org/stable/guide/learners.html#r-learners-and-hyperparameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a50aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for lambda and for optimal variance filter fraction\n",
    "library(paradox)\n",
    "par_grids = ps(regr.glmnet.lambda = p_dbl(lower = 0.05, upper = 0.1),\n",
    "               variance.filter.frac = p_dbl(lower = 0.25, upper = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify further tune settings\n",
    "library(mlr3tuning)\n",
    "tune_settings = list(terminator = trm(\"evals\", n_evals = 10),\n",
    "                      algorithm = tnr(\"grid_search\", resolution = 10),\n",
    "                      rsmp_tune = rsmp(\"cv\", folds = 5),\n",
    "                      measure = list(\"ml_l\" = msr(\"regr.mse\"),\n",
    "                                     \"ml_m\" = msr(\"regr.mse\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate new DoubleML object and execute tuning with graph learner\n",
    "set.seed(123)\n",
    "obj_dml_plr_sim_pipe_tune = DoubleMLPLR$new(dml_data_sim,\n",
    "                                            ml_l=glrn_lasso,\n",
    "                                            ml_m=glrn_lasso)\n",
    "obj_dml_plr_sim_pipe_tune$tune(param_set = list(\"ml_l\" = par_grids,\n",
    "                                                \"ml_m\" = par_grids),\n",
    "                               tune_settings=tune_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dml_plr_sim_pipe$fit()\n",
    "print(obj_dml_plr_sim_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562abbe",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Becker, M., Binder, M., Bischl, B., Lang, M., Pfisterer, F., Reich, N.G., Richter, J., Schratz, P., Sonabend, R. (2020), mlr3 book, available at https://mlr3book.mlr-org.com.\n",
    "\n",
    "Binder, M., Pfisterer, F., Lang, M., Schneider, L., Kotthof, L., and Bischl, B. (2021), mlr3pipelines - flexible machine learning pipelines in R, Journal of Machine Learning Research, 22(184): 1-7, https://jmlr.org/papers/v22/21-0281.html.\n",
    "\n",
    "Lang, M., Binder, M., Richter, J., Schratz, P., Pfisterer, F., Coors, S., Au, Q., Casalicchio, G., Kotthoff, L., Bischl, B. (2019), mlr3: A modern object-oriented machine learing framework in R. Journal of Open Source Software, [doi:10.21105/joss.01903](https://doi.org/10.21105/joss.01903).\n",
    "\n",
    "Lang, M., Au, Q., Coors, S., and Schratz, P. (2021), mlr3learners: Recommended learners for mlr3, R package, https://CRAN.R-project.org/package=mlr3learners.\n",
    "\n",
    "Sonabend, R., and Schratz, P. (2021), extralearners: Extra learners for mlr3. R package, https://mlr3extralearners.mlr-org.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba7fae8",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "**Acknowledgement**\n",
    "\n",
    "We would like to thank the developers of the [mlr3pipelines](https://mlr3pipelines.mlr-org.com/) package for providing such a powerful and easy-to-use implementation of many important ML tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
