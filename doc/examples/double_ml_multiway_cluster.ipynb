{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Multiway Cluster Robust DML\n",
    "\n",
    "This example shows how the multiway cluster roboust DML (Chiang et al. 2020) can be implemented with the DoubleML\n",
    "package.\n",
    "Chiang et al. (2020) consider double-indexed data\n",
    "\n",
    "\\begin{equation}\n",
    "\\lbrace W_{ij}: i \\in \\lbrace 1, \\ldots, N \\rbrace, j \\in \\lbrace 1, \\ldots, M \\rbrace \\rbrace\n",
    "\\end{equation}\n",
    "\n",
    "and the partially linear IV regression model (PLIV)\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Y_{ij} = D_{ij} \\theta_0 +  g_0(X_{ij}) + \\epsilon_{ij}, & &\\mathbb{E}(\\epsilon_{ij} | X_{ij}, Z_{ij}) = 0, \\\\\n",
    "Z_{ij} = m_0(X_{ij}) + v_{ij}, & &\\mathbb{E}(v_{ij} | X_{ij}) = 0.\n",
    "\\end{aligned}$$\n",
    "\n",
    "TODO: Add a few more details and the reference!\n",
    "https://arxiv.org/pdf/1909.03489.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from doubleml import DoubleMLData, DoubleMLPLIV\n",
    "from doubleml.double_ml_resampling import DoubleMLMultiwayResampling\n",
    "\n",
    "from doubleml.datasets import make_pliv_multiway_cluster_CKMS2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate multiway cluster data\n",
    "\n",
    "We use the PLIV data generating process described in Section 4.1 of Chiang et al. (2020).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "N = 25  # number of observations (first dimension)\n",
    "M = 25  # number of observations (second dimension)\n",
    "dim_X = 100  # dimension of X\n",
    "\n",
    "obj_dml_data = make_pliv_multiway_cluster_CKMS2019(N, M, dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data comes with multi index for rows (tuples with two entries)\n",
    "obj_dml_data.data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the objects of class DoubleMLData and DoubleMLPLIV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set machine learning methods for m & g\n",
    "learner = RandomForestRegressor(max_depth=2, n_estimators=10)\n",
    "ml_g = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "ml_r = clone(learner)\n",
    "\n",
    "# initialize the DoubleMLPLIV object\n",
    "dml_pliv_obj = DoubleMLPLIV(obj_dml_data,\n",
    "                            ml_g,\n",
    "                            ml_m,\n",
    "                            ml_r,\n",
    "                            score='partialling out',\n",
    "                            dml_procedure='dml1',\n",
    "                            draw_sample_splitting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split samples and transfer the sample splitting to the object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3  # number of folds\n",
    "smpl_sizes = [N, M]\n",
    "obj_dml_multiway_resampling = DoubleMLMultiwayResampling(K, smpl_sizes)\n",
    "smpls_multi_ind, smpls_lin_ind = obj_dml_multiway_resampling.split_samples()\n",
    "\n",
    "dml_pliv_obj.set_sample_splitting([smpls_lin_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model and show a summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_pliv_obj.fit()\n",
    "print(dml_pliv_obj.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of sample splitting with tuple and linear indexing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discrete color scheme\n",
    "x = sns.color_palette(\"RdBu_r\", 7)\n",
    "cMap = ListedColormap([x[0], x[3], x[6]])\n",
    "plt.rcParams['figure.figsize'] = 15, 12\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample splitting with tuples (one plot per fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "for i_split, this_split_ind in enumerate(smpls_multi_ind):\n",
    "    plt.subplot(K, K, i_split + 1)\n",
    "    df = pd.DataFrame(np.zeros([N, M]))\n",
    "    ind_array_train = np.array([*this_split_ind[0]])\n",
    "    ind_array_test = np.array([*this_split_ind[1]])\n",
    "    df.loc[ind_array_train[:, 0], ind_array_train[:, 1]] = -1.\n",
    "    df.loc[ind_array_test[:, 0], ind_array_test[:, 1]] = 1.\n",
    "\n",
    "    ax = sns.heatmap(df, cmap=cMap);\n",
    "    ax.invert_yaxis();\n",
    "    ax.set_ylim([0, M]);\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    colorbar.set_ticks([-0.667, 0, 0.667])\n",
    "    if i_split % K == (K - 1):\n",
    "        colorbar.set_ticklabels(['Nuisance', '', 'Score'])\n",
    "    else:\n",
    "        colorbar.set_ticklabels(['', '', ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample splitting with linear indexing (one column per fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros([N*M, K*K]))\n",
    "for i_split, this_split_ind in enumerate(smpls_lin_ind):\n",
    "    df.loc[this_split_ind[0], i_split] = -1.\n",
    "    df.loc[this_split_ind[1], i_split] = 1.\n",
    "\n",
    "ax = sns.heatmap(df, cmap=cMap);\n",
    "ax.invert_yaxis();\n",
    "ax.set_ylim([0, N*M]);\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_ticks([-0.667, 0, 0.667])\n",
    "colorbar.set_ticklabels(['Nuisance', '', 'Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute cluster-robust standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the same two-way indices to the evaluated score functions as to the data itself\n",
    "psi = pd.DataFrame(dml_pliv_obj.psi.squeeze(),\n",
    "                   columns=['psi']).set_index(obj_dml_data.data.index)\n",
    "psi_a = pd.DataFrame(dml_pliv_obj.psi_a.squeeze(),\n",
    "                     columns=['psi_a']).set_index(obj_dml_data.data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cluster robust standard errors according to Equations (3.4)-(3.6) in Chiang et al. (2020):\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{\\sigma}^2 = \\hat{J}^{-1} \\hat{\\Gamma} \\hat{J}^{-1},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{\\Gamma} = \\frac{1}{K^2} \\sum_{(k, \\ell) \\in[K]^2}\n",
    "\\left[ \\frac{|I_k| \\wedge |J_\\ell|}{(|I_k||J_\\ell|)^2}\n",
    "\\left(\\sum_{i \\in I_k} \\sum_{j \\in J_\\ell} \\sum_{j' \\in J_\\ell}\n",
    "\\psi(W_{ij}; \\tilde{\\theta}, \\hat{\\eta}_{k \\ell}) \\psi(W_{ij'}; \\tilde{\\theta}, \\hat{\\eta}_{k \\ell})\n",
    "+ \\sum_{i \\in I_k} \\sum_{i' \\in I_k} \\sum_{j \\in J_\\ell}\n",
    "\\psi(W_{ij}; \\tilde{\\theta}, \\hat{\\eta}_{k \\ell}) \\psi(W_{i'j}; \\tilde{\\theta}, \\hat{\\eta}_{k \\ell})\n",
    "\\right)\n",
    "\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{J} = \\frac{1}{K^2} \\sum_{(k, \\ell) \\in[K]^2} \\frac{1}{|I_k||J_\\ell|}\n",
    "\\sum_{i \\in I_k} \\sum_{j \\in J_\\ell}\n",
    "\\psi_a(W_{ij}; \\tilde{\\theta}, \\hat{\\eta}_{k \\ell}).\n",
    "\\end{aligned}\n",
    "$$\n",
    "A $(1-\\alpha)$ confidence interval is then given by (Chiang et al. 2020)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left[\n",
    "\\tilde{\\theta} \\pm \\Phi^{-1}(1-\\alpha/2) \\sqrt{\\hat{\\sigma}^2 / \\underline{C}}\n",
    "\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "with $\\underline{C} = N \\wedge M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ways = len(smpl_sizes)\n",
    "assert n_ways == 2\n",
    "gamma_hat = 0\n",
    "j_hat = 0\n",
    "for i_split, this_split_ind in enumerate(smpls_multi_ind):\n",
    "    test_ind_tuples = this_split_ind[1]\n",
    "    I_k = np.unique([xx[0] for xx in test_ind_tuples])\n",
    "    J_l = np.unique([xx[1] for xx in test_ind_tuples])\n",
    "    assert len(test_ind_tuples) == len(I_k) * len(J_l)\n",
    "    const = min(len(I_k), len(J_l))/(len(I_k) * len(J_l))**2\n",
    "    for i in I_k:\n",
    "        for j in J_l:\n",
    "            for j_ in J_l:\n",
    "                gamma_hat += const* psi.loc[i, j].values * psi.loc[i, j_].values\n",
    "    \n",
    "    for j in J_l:\n",
    "        for i in I_k:\n",
    "            for i_ in I_k:\n",
    "                gamma_hat += const* psi.loc[i, j].values * psi.loc[i_, j].values\n",
    "    j_hat += np.mean(psi_a.loc[test_ind_tuples])\n",
    "\n",
    "gamma_hat = gamma_hat / (K**2)\n",
    "j_hat = j_hat / (K**2)\n",
    "sigma_hat2 = gamma_hat / (j_hat**2)\n",
    "\n",
    "c_ = min(N, M)\n",
    "se = np.sqrt(sigma_hat2 / c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
