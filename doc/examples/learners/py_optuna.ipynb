{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50de5573",
   "metadata": {},
   "source": [
    "# Python: Hyperparametertuning with Optuna\n",
    "\n",
    "This notebook explains how to use the implmented `tune_ml_models()` method to tune hyperparameters using the [Optuna](https://optuna.org/) package.\n",
    "\n",
    "In this example, we will focus on the [DoubleMLAPO](https://docs.doubleml.org/stable/api/generated/doubleml.irm.DoubleMLAPO.html#doubleml.irm.DoubleMLAPO) model to estimate average potential outcomes (APOs) in an interactive regression model (see [DoubleMLIRM](https://docs.doubleml.org/stable/guide/models.html#binary-interactive-regression-model-irm)).\n",
    "\n",
    "The goal is to estimate the average potential outcome\n",
    "\n",
    " $$\\theta_0 =\\mathbb{E}[Y(d)]$$\n",
    "\n",
    "for a given treatment level $d$ and and discrete valued treatment $D$.\n",
    "\n",
    "For a more detailed description of the DoubleMLAPO model, see [Average Potential Outcome Model](https://docs.doubleml.org/stable/guide/models.html#average-potential-outcomes-apos) or [Example Gallery](https://docs.doubleml.org/stable/examples/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e56470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.io import show\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "from doubleml.data import DoubleMLData\n",
    "from doubleml.irm import DoubleMLAPO\n",
    "from doubleml.irm.datasets import make_irm_data_discrete_treatments\n",
    "\n",
    "palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cbe4c",
   "metadata": {},
   "source": [
    "## Data Generating Process (DGP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdfa1ad",
   "metadata": {},
   "source": [
    "At first, let us generate data according to the [make_irm_data_discrete_treatments](https://docs.doubleml.org/dev/api/datasets.html#dataset-generators) data generating process. The process generates data with a continuous treatment variable and contains the true individual treatment effects (ITEs) with respect to option of not getting treated.\n",
    "\n",
    "According to the continuous treatment variable, the treatment is discretized into multiple levels, based on quantiles. Using the *oracle* ITEs, enables the comparison to the true APOs and averate treatment effects (ATEs) for the different levels of the treatment variable.\n",
    "\n",
    "**Remark:** The average potential outcome model does not require an underlying continuous treatment variable. The model will work identically if the treatment variable is discrete by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e246dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Individual effects in each group:\n",
      "[ 0.    3.44  9.32 10.49]\n",
      "\n",
      "Average Potential Outcomes in each group:\n",
      "[210.05 213.49 219.38 220.54]\n",
      "\n",
      "Levels and their counts:\n",
      "(array([0., 1., 2., 3.]), array([171, 110, 109, 110]))\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_obs = 500\n",
    "n_levels = 3\n",
    "treatment_lvl = 1.0\n",
    "\n",
    "np.random.seed(42)\n",
    "data_apo = make_irm_data_discrete_treatments(n_obs=n_obs,n_levels=n_levels, linear=False)\n",
    "\n",
    "y0 = data_apo['oracle_values']['y0']\n",
    "cont_d = data_apo['oracle_values']['cont_d']\n",
    "ite = data_apo['oracle_values']['ite']\n",
    "d = data_apo['d']\n",
    "potential_level = data_apo['oracle_values']['potential_level']\n",
    "level_bounds = data_apo['oracle_values']['level_bounds']\n",
    "\n",
    "average_ites = np.full(n_levels + 1, np.nan)\n",
    "apos = np.full(n_levels + 1, np.nan)\n",
    "mid_points = np.full(n_levels, np.nan)\n",
    "\n",
    "for i in range(n_levels + 1):\n",
    "    average_ites[i] = np.mean(ite[d == i]) * (i > 0)\n",
    "    apos[i] = np.mean(y0) + average_ites[i]\n",
    "\n",
    "print(f\"Average Individual effects in each group:\\n{np.round(average_ites,2)}\\n\")\n",
    "print(f\"Average Potential Outcomes in each group:\\n{np.round(apos,2)}\\n\")\n",
    "print(f\"Levels and their counts:\\n{np.unique(d, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd46dba",
   "metadata": {},
   "source": [
    "As for all [DoubleML](https://docs.doubleml.org/stable/index.html) models, we specify a [DoubleMLData](https://docs.doubleml.org/stable/api/generated/doubleml.data.DoubleMLData.html) object to handle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98bf812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['x0', 'x1', 'x2', 'x3', 'x4']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Columns: 7 entries, y to x4\n",
      "dtypes: float64(7)\n",
      "memory usage: 27.5 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = data_apo['y']\n",
    "x = data_apo['x']\n",
    "d = data_apo['d']\n",
    "df_apo = pd.DataFrame(\n",
    "    np.column_stack((y, d, x)),\n",
    "    columns=['y', 'd'] + ['x' + str(i) for i in range(data_apo['x'].shape[1])]\n",
    ")\n",
    "\n",
    "dml_data = DoubleMLData(df_apo, 'y', 'd')\n",
    "print(dml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fd594",
   "metadata": {},
   "source": [
    "## Basic Tuning Example\n",
    "\n",
    "At first, we will take a look at a very basic tuning example without much customization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8478ec",
   "metadata": {},
   "source": [
    "### Define Nuisance Learners\n",
    "\n",
    "For our example, we will choose [LightGBM](https://lightgbm.readthedocs.io/en/stable/) learners, which are typical non-parametric choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae487e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_g = LGBMRegressor(random_state=314, verbose=-1)\n",
    "ml_m = LGBMClassifier(random_state=314, verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a336e1",
   "metadata": {},
   "source": [
    "### Untuned Model\n",
    "\n",
    "Now let us take a look at the standard workflow, focusing on a single treatment level and using default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ea7d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>211.232659</td>\n",
       "      <td>15.657431</td>\n",
       "      <td>13.490888</td>\n",
       "      <td>1.769555e-41</td>\n",
       "      <td>180.544657</td>\n",
       "      <td>241.920661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef    std err          t         P>|t|       2.5 %      97.5 %\n",
       "d  211.232659  15.657431  13.490888  1.769555e-41  180.544657  241.920661"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_obj_untuned = DoubleMLAPO(\n",
    "    dml_data,\n",
    "    ml_g,\n",
    "    ml_m,\n",
    "    treatment_level=treatment_lvl,\n",
    ")\n",
    "\n",
    "dml_obj_untuned.fit()\n",
    "dml_obj_untuned.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc29fc",
   "metadata": {},
   "source": [
    "### Hyperparametertuning\n",
    "\n",
    "Now, let us take a look at the basic hyperparametertuning. We will initialize a separate model to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ff8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned = DoubleMLAPO(\n",
    "    dml_data,\n",
    "    ml_g,\n",
    "    ml_m,\n",
    "    treatment_level=treatment_lvl,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a8a52",
   "metadata": {},
   "source": [
    "The required input for tuning is a parameter space dictionary for the hyperparameters for each learner that should be tuned.\n",
    "This dictionary should include a callable for each learner you want to have (only a subset is also possible, i.e. only tuning `ml_g`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d36a4a",
   "metadata": {},
   "source": [
    "The parameter spaces should be a callable and suggest the search spaces via a `trial` object.\n",
    "\n",
    "Generally, the hyperparameter structure should follow the definitions in [Optuna](https://optuna.org/#key_features), but instead of the objective the hyperparameters have to be specified as a callable. The corresponding DoubleML object then assigns a corresponding objective for each learning using the supplied parameter space.\n",
    "\n",
    "To keep this example fast and simple, we keep the `n_estimators` fix and only tune a small number of other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74257e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter space for the outcome regression tuning\n",
    "def ml_g_params(trial):\n",
    "    return {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "# parameter space for the propensity score tuning\n",
    "def ml_m_params(trial):\n",
    "    return {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "param_space = {\n",
    "    'ml_g': ml_g_params,\n",
    "    'ml_m': ml_m_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2ff6c",
   "metadata": {},
   "source": [
    "To tune the hyperparameters the `tune_ml_models()` with the `ml_param_space` argument should be called.\n",
    "Further, to define the number of trials and other optuna options you can use the `optuna_setttings` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe81ad26",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_dml_tune_optuna() missing 1 required positional argument: 'params_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m optuna_settings = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_trials\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m100\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshow_progress_bar\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      4\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdml_obj_tuned\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune_ml_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mml_param_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptuna_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptuna_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/doubleml/double_ml.py:1119\u001b[39m, in \u001b[36mDoubleML.tune_ml_models\u001b[39m\u001b[34m(self, ml_param_space, scoring_methods, cv, set_as_params, return_tune_res, optuna_settings)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28mself\u001b[39m._dml_data.set_x_d(\u001b[38;5;28mself\u001b[39m._dml_data.d_cols[i_d])\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# tune hyperparameters (globally, not fold-specific)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nuisance_tuning_optuna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpanded_param_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring_methods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_splitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptuna_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m filtered_results = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m res.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m requested_learners}\n\u001b[32m   1127\u001b[39m tuning_res[i_d] = filtered_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/doubleml/irm/apo.py:484\u001b[39m, in \u001b[36mDoubleMLAPO._nuisance_tuning_optuna\u001b[39m\u001b[34m(self, optuna_params, scoring_methods, cv, optuna_settings)\u001b[39m\n\u001b[32m    482\u001b[39m g_lvl0_param_grid = optuna_params[\u001b[33m\"\u001b[39m\u001b[33mml_g_d_lvl0\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    483\u001b[39m g_lvl0_scoring = scoring_methods[\u001b[33m\"\u001b[39m\u001b[33mml_g_d_lvl0\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m g_d_lvl0_tune_res = \u001b[43m_dml_tune_optuna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_lvl0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdx_lvl0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml_g\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mg_lvl0_param_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mg_lvl0_scoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptuna_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearner_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml_g_d_lvl0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    495\u001b[39m x_lvl1 = x[mask_lvl1, :]\n\u001b[32m    496\u001b[39m y_lvl1 = y[mask_lvl1]\n",
      "\u001b[31mTypeError\u001b[39m: _dml_tune_optuna() missing 1 required positional argument: 'params_name'"
     ]
    }
   ],
   "source": [
    "optuna_settings = {\n",
    "    'n_trials': 100,\n",
    "    'show_progress_bar': True,\n",
    "}\n",
    "\n",
    "dml_obj_tuned.tune_ml_models(\n",
    "    ml_param_space=param_space,\n",
    "    optuna_settings=optuna_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345dc41",
   "metadata": {},
   "source": [
    "Per default, the model will set the best hyperparameters automatically (identical hyperparameters for each fold), and you can directly call the `fit()` method afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned.fit()\n",
    "dml_obj_tuned.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48b7d7",
   "metadata": {},
   "source": [
    "**Remark**: Even if the initialization and tuning only requires the learners `ml_g` and `ml_m`, the models in the `irm` submodule generally, copy the learner for `ml_g` and fit different response surfaces for treatment and control (or not-treatment) groups. These different learners are tuned separately but with the same parameter space. To see which parameter spaces can be tuned you can take a look at the `params_names` property.\n",
    "\n",
    "In this example, we specified the parameter spaces for `ml_m` and `ml_g`, but actually three sets of hyperparameters were tuned, i.e. `ml_m`, `ml_g_d_lvl0` and `ml_g_d_lvl1` (two response surfaces for the outcome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a70f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned.params_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6aa5f6",
   "metadata": {},
   "source": [
    "Each hyperparameter combination is set for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aaf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bccb213",
   "metadata": {},
   "source": [
    "### Comparison\n",
    " \n",
    "Let us compare the results for both models. If we take a look at the predictive performance of the learners, the main difference can be observed in the log loss of the propensity score `ml_m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a95719",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_untuned.evaluate_learners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e08448",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned.evaluate_learners()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58e994",
   "metadata": {},
   "source": [
    "As a result the standard error is reduced and confidence intervals are much tighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_untuned = dml_obj_untuned.coef[0]\n",
    "theta_tuned = dml_obj_tuned.coef[0]\n",
    "ci_untuned = dml_obj_untuned.confint()\n",
    "ci_tuned = dml_obj_tuned.confint()\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Untuned', 'Tuned'],\n",
    "    'theta': [theta_untuned, theta_tuned],\n",
    "    'ci_lower': [ci_untuned.iloc[0, 0], ci_tuned.iloc[0, 0]],\n",
    "    'ci_upper': [ci_untuned.iloc[0, 1], ci_tuned.iloc[0, 1]]\n",
    "}\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(f\"\\nTrue APO at treatment level {treatment_lvl}: {apos[int(treatment_lvl)]:.4f}\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(0, df_comparison.loc[0, 'theta'], \n",
    "             yerr=[[df_comparison.loc[0, 'theta'] - df_comparison.loc[0, 'ci_lower']], \n",
    "                   [df_comparison.loc[0, 'ci_upper'] - df_comparison.loc[0, 'theta']]], \n",
    "             fmt='o', capsize=5, capthick=2, ecolor=palette[0], color=palette[0], \n",
    "             label='Untuned', markersize=10, zorder=2)\n",
    "plt.errorbar(1, df_comparison.loc[1, 'theta'], \n",
    "             yerr=[[df_comparison.loc[1, 'theta'] - df_comparison.loc[1, 'ci_lower']], \n",
    "                   [df_comparison.loc[1, 'ci_upper'] - df_comparison.loc[1, 'theta']]], \n",
    "             fmt='o', capsize=5, capthick=2, ecolor=palette[1], color=palette[1], \n",
    "             label='Tuned', markersize=10, zorder=2)\n",
    "plt.axhline(y=apos[int(treatment_lvl)], color=palette[4], linestyle='--', \n",
    "            linewidth=2, label='True APO', zorder=1)\n",
    "\n",
    "plt.title(f'Estimated APO Coefficients with and without Tuning for Treatment Level {treatment_lvl}')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks([0, 1], ['Untuned', 'Tuned'])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279c7a0",
   "metadata": {},
   "source": [
    "## Detailed Hyperparameter Tuning Guide\n",
    "\n",
    "In this section, we explore tuning options in more detail and employ a more complicated learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7d75f",
   "metadata": {},
   "source": [
    "### Define Nuisance Learners\n",
    "\n",
    "For our example, we will choose [Pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline) to generate a complex [StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) or [StackingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76937e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_regressors = [\n",
    "    ('linear_regression', LinearRegression()),\n",
    "    ('lgbm', LGBMRegressor(random_state=42, verbose=-1))\n",
    "]\n",
    "\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=base_regressors,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "ml_g_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('stacking', stacking_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifiers = [\n",
    "    ('logistic_regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(random_state=42, verbose=-1))\n",
    "]\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=base_classifiers,\n",
    "    final_estimator=LogisticRegression(),\n",
    ")\n",
    "\n",
    "ml_m_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('stacking', stacking_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49756f0",
   "metadata": {},
   "source": [
    "### Untuned Model with Pipeline\n",
    "\n",
    "Now let us take a look at the standard workflow, focusing on a single treatment level and using default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf47ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_untuned_pipeline = DoubleMLAPO(\n",
    "    dml_data,\n",
    "    ml_g_pipeline,\n",
    "    ml_m_pipeline,\n",
    "    treatment_level=treatment_lvl,\n",
    ")\n",
    "\n",
    "dml_obj_untuned_pipeline.fit()\n",
    "dml_obj_untuned_pipeline.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fb3b6",
   "metadata": {},
   "source": [
    "### Hyperparametertuning with Pipelines\n",
    "\n",
    "Now, let us take a look at more complex. Again, we will initialize a separate model to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33bf5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned_pipeline = DoubleMLAPO(\n",
    "    dml_data,\n",
    "    ml_g_pipeline,\n",
    "    ml_m_pipeline,\n",
    "    treatment_level=treatment_lvl,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0febfc",
   "metadata": {},
   "source": [
    "As before the tuning input is a parameter space dictionary for the hyperparameters for each learner that should be tuned.\n",
    "This dictionary should include a callable for each learner you want to have (only a subset is also possible, i.e. only tuning `ml_g`).\n",
    "\n",
    "Since we have now a much more complicated learner the tuning inputs have to passed correctly into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter space for the outcome regression tuning\n",
    "def ml_g_params_pipeline(trial):\n",
    "    return {\n",
    "        'stacking__lgbm__n_estimators': 100,\n",
    "        'stacking__lgbm__learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'stacking__lgbm__max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "        'stacking__lgbm__min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'stacking__final_estimator__alpha': trial.suggest_float('alpha', 0.001, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "# parameter space for the propensity score tuning\n",
    "def ml_m_params_pipeline(trial):\n",
    "    return {\n",
    "        'stacking__lgbm__n_estimators': 100,\n",
    "        'stacking__lgbm__learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'stacking__lgbm__max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "        'stacking__lgbm__min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'stacking__final_estimator__C': trial.suggest_float('C', 0.01, 100.0, log=True),\n",
    "        'stacking__final_estimator__max_iter': 1000,\n",
    "    }\n",
    "\n",
    "param_space_pipeline = {\n",
    "    'ml_g': ml_g_params_pipeline,\n",
    "    'ml_m': ml_m_params_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf12fb1",
   "metadata": {},
   "source": [
    "As before, we can pass the arguments for optuna via `optuna_settings`.  For possible option please take a look at the [Optuna Documenation](https://optuna.readthedocs.io/en/stable/index.html). For each learner you can pass local settings which will override the settings.\n",
    "\n",
    "Here, we will reduce the number of trials for `ml_g` as it did already perform quite well before.\n",
    "In principle, we could also use different [samplers](https://optuna.readthedocs.io/en/stable/reference/samplers/index.html), but generally we recommend to use the [TPESampler](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html), which is used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "optuna_settings_pipeline = {\n",
    "    'n_trials': 100,\n",
    "    'show_progress_bar': True,\n",
    "    'ml_g': {\n",
    "        'n_trials': 50\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5cc9a",
   "metadata": {},
   "source": [
    "As before, we can tune the hyperparameters via the `tune_ml_models()` method. If we would like to inspect the optuna.study results, we can return all tuning results via the `return_tune_res` argument.\n",
    "\n",
    "We will have a detailed look at the returned results later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = dml_obj_tuned.tune_ml_models(\n",
    "    ml_param_space=param_space_pipeline,\n",
    "    optuna_settings=optuna_settings_pipeline,\n",
    "    return_tune_res=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_obj_tuned_pipeline.fit()\n",
    "dml_obj_tuned_pipeline.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4037bd4",
   "metadata": {},
   "source": [
    "**Remark**: All settings (`optuna_settings` and `ml_param_space`) can also be set on the `params_names` level instead of the `learner_names` level, i.e. `ml_g_d_lvl1` instead of `ml_g`. Generally, more specific settings will override more general settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e73bb",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients and confidence intervals for all models\n",
    "theta_untuned = dml_obj_untuned.coef[0]\n",
    "theta_tuned = dml_obj_tuned.coef[0]\n",
    "theta_untuned_pipeline = dml_obj_untuned_pipeline.coef[0]\n",
    "theta_tuned_pipeline = dml_obj_tuned_pipeline.coef[0]\n",
    "\n",
    "ci_untuned = dml_obj_untuned.confint()\n",
    "ci_tuned = dml_obj_tuned.confint()\n",
    "ci_untuned_pipeline = dml_obj_untuned_pipeline.confint()\n",
    "ci_tuned_pipeline = dml_obj_tuned_pipeline.confint()\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Untuned', 'Tuned', 'Untuned Pipeline', 'Tuned Pipeline'],\n",
    "    'theta': [theta_untuned, theta_tuned, theta_untuned_pipeline, theta_tuned_pipeline],\n",
    "    'ci_lower': [ci_untuned.iloc[0, 0], ci_tuned.iloc[0, 0], \n",
    "                 ci_untuned_pipeline.iloc[0, 0], ci_tuned_pipeline.iloc[0, 0]],\n",
    "    'ci_upper': [ci_untuned.iloc[0, 1], ci_tuned.iloc[0, 1],\n",
    "                 ci_untuned_pipeline.iloc[0, 1], ci_tuned_pipeline.iloc[0, 1]]\n",
    "}\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(f\"\\nTrue APO at treatment level {treatment_lvl}: {apos[int(treatment_lvl)]:.4f}\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Create plot with all 4 models\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(len(df_comparison)):\n",
    "    plt.errorbar(i, df_comparison.loc[i, 'theta'], \n",
    "                 yerr=[[df_comparison.loc[i, 'theta'] - df_comparison.loc[i, 'ci_lower']], \n",
    "                       [df_comparison.loc[i, 'ci_upper'] - df_comparison.loc[i, 'theta']]], \n",
    "                 fmt='o', capsize=5, capthick=2, ecolor=palette[i], color=palette[i], \n",
    "                 label=df_comparison.loc[i, 'Model'], markersize=10, zorder=2)\n",
    "\n",
    "plt.axhline(y=apos[int(treatment_lvl)], color=palette[4], linestyle='--', \n",
    "            linewidth=2, label='True APO', zorder=1)\n",
    "\n",
    "plt.title('Estimated APO Coefficients: Comparison Across All Models')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.xticks(range(4), df_comparison['Model'], rotation=15, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8d51b",
   "metadata": {},
   "source": [
    "### Detailed Tuning Result Analysis\n",
    "\n",
    "The `tune_ml_models()` method creates several [Optuna Studies](https://optuna.readthedocs.io/en/stable/reference/study.html), which can be inspected in detail via the returned results.\n",
    "\n",
    "The results are a list of dictionaries, which contain a corresponding `DMLOptunaResult` for each treatment variable on the `param_names` level, i.e. for each [Optuna Study](https://optuna.readthedocs.io/en/stable/reference/study.html) object a separate `DMLOptunaResult` is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna results for the single treatment\n",
    "print(tuning_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acd97b",
   "metadata": {},
   "source": [
    "In this example, we take a more detailed look in the tuning of `ml_m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e92730",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuning_results[0]['ml_m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85cfecd",
   "metadata": {},
   "source": [
    "As we have access to the saved [Optuna Study](https://optuna.readthedocs.io/en/stable/reference/study.html) object, it is possible to access all trials and hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_m_study = tuning_results[0]['ml_m'].study_\n",
    "ml_m_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f6d0f",
   "metadata": {},
   "source": [
    " Additionally, we can access all [Optuna visualization options](https://optuna.readthedocs.io/en/stable/reference/visualization/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(ml_m_study)\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_parallel_coordinate(ml_m_study)\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(ml_m_study)\n",
    "show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
