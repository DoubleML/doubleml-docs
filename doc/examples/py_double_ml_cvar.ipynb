{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Python: Conditional Value at Risk of potential outcomes\n",
    "In this example, we illustrate how the [DoubleML](https://docs.doubleml.org/stable/index.html) package can be used to estimate the conditional Value at Risk of potential outcomes. The estimation is based on [Kallus  et al. (2019)](https://arxiv.org/abs/1912.12945)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data\n",
    "We define a data generating process to create synthetic data to compare the estimates to the true effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "import multiprocessing\n",
    "\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data is generated as a location-scale model with\n",
    "\n",
    "$$Y_i = \\text{loc}(D_i,X_i) + \\text{scale}(D_i,X_i)\\cdot\\varepsilon_i,$$\n",
    "\n",
    "where $X_i\\sim\\mathcal{U}[-1,1]^{p}$ and $\\varepsilon_i \\sim \\mathcal{N}(0,1)$.\n",
    "Further, the location and scale are determined according to the following functions\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{loc}(d,x) &:= 0.5d + 2dx_5 + 2\\cdot 1\\{x_2 > 0.1\\} - 1.7\\cdot 1\\{x_1x_3 > 0\\} - 3x_4 \\\\\n",
    "\\text{scale}(d,x) &:= \\sqrt{0.5d + 0.3dx_1 + 2},\n",
    "\\end{aligned}$$\n",
    "\n",
    "and the treatment takes the following form\n",
    "\n",
    "$$D_i = 1_{\\{(X_2 - X_4 + 1.5\\cdot 1\\{x_1 > 0\\} + \\epsilon_i > 0)\\}}$$\n",
    "\n",
    "with $\\epsilon_i \\sim \\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_loc(D, X):\n",
    "  loc = 0.5*D + 2*D*X[:,4] + 2.0*(X[:,1] > 0.1) - 1.7*(X[:,0] * X[:,2] > 0) - 3*X[:,3]\n",
    "  return loc\n",
    "\n",
    "def f_scale(D, X):\n",
    "  scale = np.sqrt(0.5*D + 0.3*D*X[:,1] + 2)\n",
    "  return scale\n",
    "\n",
    "def dgp(n=200, p=5):\n",
    "    X = np.random.uniform(-1,1,size=[n,p])\n",
    "    D = ((X[:,1 ] - X[:,3] + 1.5*(X[:,0] > 0) + np.random.normal(size=n)) > 0)*1.0\n",
    "    epsilon = np.random.normal(size=n)\n",
    "\n",
    "    Y = f_loc(D, X) + f_scale(D, X)*epsilon\n",
    "\n",
    "    return Y, X, D, epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can calculate the true conditional value at risk through simulations. Here, we will just approximate the true conditional value at risk for the potential outcomes for a range of quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau_vec = np.arange(0.1,0.95,0.05)\n",
    "p = 5\n",
    "n_true = int(10e+6)\n",
    "\n",
    "_, X_true, _, epsilon_true = dgp(n=n_true, p = p)\n",
    "D1 = np.ones(n_true)\n",
    "D0 = np.zeros(n_true)\n",
    "\n",
    "Y1 = f_loc(D1, X_true) + f_scale(D1, X_true)*epsilon_true\n",
    "Y0 = f_loc(D0, X_true) + f_scale(D0, X_true)*epsilon_true\n",
    "\n",
    "Y1_quant = np.quantile(Y1, q=tau_vec)\n",
    "Y0_quant = np.quantile(Y0, q=tau_vec)\n",
    "\n",
    "Y1_cvar = [Y1[Y1 >= quant].mean() for quant in Y1_quant]\n",
    "Y0_cvar = [Y0[Y0 >= quant].mean() for quant in Y0_quant]\n",
    "\n",
    "print(f'Conditional Value at Risk Y(0): {Y0_cvar}')\n",
    "print(f'Conditional Value at Risk Y(1): {Y1_cvar}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let us generate $n=5000$ observations and convert them to a [DoubleMLData](https://docs.doubleml.org/stable/api/generated/doubleml.DoubleMLData.html) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 5000\n",
    "np.random.seed(42)\n",
    "Y, X, D, _ = dgp(n=n,p=p)\n",
    "obj_dml_data = dml.DoubleMLData.from_arrays(X, Y, D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conditional Value at Risk (CVaR)\n",
    "Next, we can initialize our two machine learning algorithms to train the different nuisance elements (remark that in contrast to potential quantile estimation `ml_g` is a regressor). Then we can initialize the `DoubleMLCVAR` objects and call `fit()` to estimate the relevant parameters. To obtain confidence intervals, we can use the `confint()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_g = LGBMRegressor(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "ml_m = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "\n",
    "CVAR_0 = np.full((len(tau_vec)), np.nan)\n",
    "CVAR_1 = np.full((len(tau_vec)), np.nan)\n",
    "\n",
    "ci_CVAR_0 = np.full((len(tau_vec),2), np.nan)\n",
    "ci_CVAR_1 = np.full((len(tau_vec),2), np.nan)\n",
    "\n",
    "for idx_tau, tau in enumerate(tau_vec):\n",
    "    print(f'Quantile: {tau}')\n",
    "    dml_CVAR_0 = dml.DoubleMLCVAR(obj_dml_data,\n",
    "                                ml_g, ml_m,\n",
    "                                quantile=tau,\n",
    "                                treatment=0,\n",
    "                                n_folds=5)\n",
    "    dml_CVAR_1 = dml.DoubleMLCVAR(obj_dml_data,\n",
    "                                ml_g, ml_m,\n",
    "                                quantile=tau,\n",
    "                                treatment=1,\n",
    "                                n_folds=5)\n",
    "\n",
    "    dml_CVAR_0.fit()\n",
    "    dml_CVAR_1.fit()\n",
    "\n",
    "    ci_CVAR_0[idx_tau, :] = dml_CVAR_0.confint(level=0.95).to_numpy()\n",
    "    ci_CVAR_1[idx_tau, :] = dml_CVAR_1.confint(level=0.95).to_numpy()\n",
    "\n",
    "    CVAR_0[idx_tau] = dml_CVAR_0.coef\n",
    "    CVAR_1[idx_tau] = dml_CVAR_1.coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, let us take a look at the estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {\"Quantile\": tau_vec, \"CVaR Y(0)\": Y0_cvar, \"CVaR Y(1)\": Y1_cvar,\n",
    "        \"DML CVaR Y(0)\": CVAR_0, \"DML CVaR Y(1)\": CVAR_1,\n",
    "        \"DML CVaR Y(0) lower\": ci_CVAR_0[:, 0], \"DML CVaR Y(0) upper\": ci_CVAR_0[:, 1],\n",
    "        \"DML CVaR Y(1) lower\": ci_CVAR_1[:, 0], \"DML CVaR Y(1) upper\": ci_CVAR_1[:, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, (ax1, ax2) = plt.subplots(1 ,2)\n",
    "ax1.grid(); ax2.grid()\n",
    "\n",
    "ax1.plot(df['Quantile'],df['DML CVaR Y(0)'], color='violet', label='Estimated CVaR Y(0)')\n",
    "ax1.plot(df['Quantile'],df['CVaR Y(0)'], color='green', label='True CVaR Y(0)')\n",
    "ax1.fill_between(df['Quantile'], df['DML CVaR Y(0) lower'], df['DML CVaR Y(0) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(-2, 6)\n",
    "\n",
    "ax2.plot(df['Quantile'],df['DML CVaR Y(1)'], color='violet', label='Estimated CVaR Y(1)')\n",
    "ax2.plot(df['Quantile'],df['CVaR Y(1)'], color='green', label='True CVaR Y(1)')\n",
    "ax2.fill_between(df['Quantile'], df['DML CVaR Y(1) lower'], df['DML CVaR Y(1) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(-2, 6)\n",
    "\n",
    "fig.suptitle('Conditional Value at Risk', fontsize=16)\n",
    "fig.supxlabel('Quantile')\n",
    "_ = fig.supylabel('CVaR and 95%-CI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVaR Treatment Effects\n",
    "In most cases, we want to evaluate the treatment effect on the CVaR as the difference between potential CVaRs.\n",
    "To estimate the treatment effect, we can use the `DoubleMLQTE` object and specify `CVaR` as the score. \n",
    "\n",
    "As for quantile treatment effects, different quantiles can be estimated in parallel with `n_jobs_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "cores_used = np.min([5, n_cores - 1])\n",
    "print(f\"Number of Cores used: {cores_used}\")\n",
    "\n",
    "dml_CVAR = dml.DoubleMLQTE(obj_dml_data,\n",
    "                           ml_g,\n",
    "                           ml_m,\n",
    "                           score='CVaR',\n",
    "                           quantiles=tau_vec,\n",
    "                           n_folds=5)\n",
    "dml_CVAR.fit(n_jobs_models=cores_used)\n",
    "print(dml_CVAR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for standard `DoubleMLCVAR` objects, we can construct valid confidencebands with the `confint()` method. Additionally, it might be helpful to construct uniformly valid confidence regions via boostrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_CVAR = dml_CVAR.confint(level=0.95, joint=False)\n",
    "\n",
    "dml_CVAR.bootstrap(n_rep_boot=2000)\n",
    "ci_joint_CVAR = dml_CVAR.confint(level=0.95, joint=True)\n",
    "ci_joint_CVAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare the predicted treatment effect with the true treatment effect on the CVaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVAR = np.array(Y1_cvar) - np.array(Y0_cvar)\n",
    "data = {\"Quantile\": tau_vec, \"CVaR\": CVAR, \"DML CVaR\": dml_CVAR.coef,\n",
    "        \"DML CVaR pointwise lower\": ci_CVAR['2.5 %'], \"DML CVaR pointwise upper\": ci_CVAR['97.5 %'],\n",
    "        \"DML CVaR joint lower\": ci_joint_CVAR['2.5 %'], \"DML CVaR joint upper\": ci_joint_CVAR['97.5 %']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(df['Quantile'],df['DML CVaR'], color='violet', label='Estimated CVaR')\n",
    "ax.plot(df['Quantile'],df['CVaR'], color='green', label='True CVaR')\n",
    "ax.fill_between(df['Quantile'], df['DML CVaR pointwise lower'], df['DML CVaR pointwise upper'], color='violet', alpha=.3, label='Pointwise Confidence Interval')\n",
    "ax.fill_between(df['Quantile'], df['DML CVaR joint lower'], df['DML CVaR joint upper'], color='violet', alpha=.2, label='Joint Confidence Interval')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Conditional Value at Risk', fontsize=16)\n",
    "plt.xlabel('Quantile')\n",
    "_ = plt.ylabel('QTE and 95%-CI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "04413e1efd13b5e2aaedccc5facec5686292d28983ef24fa021a12c73bd6369e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
