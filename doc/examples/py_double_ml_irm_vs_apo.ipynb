{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: IRM and APO Model Comparison\n",
    "\n",
    "In this simple example, we illustrate how the (binary) [DoubleMLIRM](https://docs.doubleml.org/stable/guide/models.html#binary-interactive-regression-model-irm) model and the [DoubleMLAPOS](https://docs.doubleml.org/stable/guide/models.html#average-potential-outcomes-apos-for-multiple-treatment-levels) differ.\n",
    "\n",
    "More specifically, we focus on the `causal_contrast()` method of [DoubleMLAPOS](https://docs.doubleml.org/stable/guide/models.html#average-potential-outcomes-apos-for-multiple-treatment-levels) in a binary setting to highlight, when both methods coincide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "from doubleml.datasets import make_irm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We rely on the [make_irm_data](https://docs.doubleml.org/stable/api/generated/doubleml.datasets.make_irm_data.html) go generate data with a binary treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.541060</td>\n",
       "      <td>0.195963</td>\n",
       "      <td>0.835750</td>\n",
       "      <td>1.180271</td>\n",
       "      <td>0.655959</td>\n",
       "      <td>1.044239</td>\n",
       "      <td>-1.214769</td>\n",
       "      <td>-2.160836</td>\n",
       "      <td>-2.196655</td>\n",
       "      <td>-2.037529</td>\n",
       "      <td>4.704558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.340235</td>\n",
       "      <td>2.319420</td>\n",
       "      <td>2.193375</td>\n",
       "      <td>1.139508</td>\n",
       "      <td>1.458814</td>\n",
       "      <td>0.493195</td>\n",
       "      <td>1.313870</td>\n",
       "      <td>0.127337</td>\n",
       "      <td>0.418400</td>\n",
       "      <td>1.070433</td>\n",
       "      <td>6.113952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.563563</td>\n",
       "      <td>-1.480199</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>-0.400113</td>\n",
       "      <td>0.757559</td>\n",
       "      <td>0.131483</td>\n",
       "      <td>-0.574160</td>\n",
       "      <td>0.067212</td>\n",
       "      <td>-0.427654</td>\n",
       "      <td>-1.342117</td>\n",
       "      <td>-0.226479</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044176</td>\n",
       "      <td>-2.122421</td>\n",
       "      <td>-1.526582</td>\n",
       "      <td>-1.892828</td>\n",
       "      <td>-1.777867</td>\n",
       "      <td>-1.425325</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.487524</td>\n",
       "      <td>-0.579197</td>\n",
       "      <td>-0.752909</td>\n",
       "      <td>0.367366</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.896263</td>\n",
       "      <td>-1.198493</td>\n",
       "      <td>-1.285483</td>\n",
       "      <td>-1.361623</td>\n",
       "      <td>-2.921778</td>\n",
       "      <td>-2.026966</td>\n",
       "      <td>-1.107156</td>\n",
       "      <td>-0.498122</td>\n",
       "      <td>0.568287</td>\n",
       "      <td>1.004542</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  0.541060  0.195963  0.835750  1.180271  0.655959  1.044239 -1.214769   \n",
       "1  1.340235  2.319420  2.193375  1.139508  1.458814  0.493195  1.313870   \n",
       "2 -0.563563 -1.480199  0.943548 -0.400113  0.757559  0.131483 -0.574160   \n",
       "3 -0.044176 -2.122421 -1.526582 -1.892828 -1.777867 -1.425325  0.020272   \n",
       "4 -1.896263 -1.198493 -1.285483 -1.361623 -2.921778 -2.026966 -1.107156   \n",
       "\n",
       "         X8        X9       X10         y    d  \n",
       "0 -2.160836 -2.196655 -2.037529  4.704558  1.0  \n",
       "1  0.127337  0.418400  1.070433  6.113952  1.0  \n",
       "2  0.067212 -0.427654 -1.342117 -0.226479  0.0  \n",
       "3  0.487524 -0.579197 -0.752909  0.367366  0.0  \n",
       "4 -0.498122  0.568287  1.004542  0.913585  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_obs = 2000\n",
    "\n",
    "np.random.seed(42)\n",
    "df = make_irm_data(\n",
    "    n_obs=n_obs,\n",
    "    dim_x=10,\n",
    "    theta=5.0,\n",
    "    return_type='DataFrame'\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the ``DoubleMLData`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_data = dml.DoubleMLData(\n",
    "    df,\n",
    "    y_col='y',\n",
    "    d_cols='d'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learners and Hyperparameters\n",
    "\n",
    "To simplify the comparison and keep the variation in learners as small as possible, we will use linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "n_rep = 1\n",
    "\n",
    "dml_kwargs = {\n",
    "    \"obj_dml_data\": dml_data,\n",
    "    \"ml_g\": LinearRegression(),\n",
    "    \"ml_m\": LogisticRegression(random_state=42),\n",
    "    \"n_folds\": n_folds,\n",
    "    \"n_rep\": n_rep,\n",
    "    \"trimming_threshold\": 1e-2,\n",
    "    \"draw_sample_splitting\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:**\n",
    "All results rely on the exact same predictions for the machine learning algorithms. If the more than two treatment levels exists the `DoubleMLAPOS` model fit multiple binary models such that the combined model might differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, to remove all uncertainty from sample splitting, we will rely on externally provided sample splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doubleml.utils import DoubleMLResampling\n",
    "\n",
    "rskf = DoubleMLResampling(\n",
    "    n_folds=n_folds,\n",
    "    n_rep=n_rep,\n",
    "    n_obs=n_obs,\n",
    "    stratify=df['d'],\n",
    ")\n",
    "all_smpls = rskf.split_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Treatment Effect\n",
    "\n",
    "Comparing the effect estimates for the `DoubleMLIRM` and `causal_contrasts` of the `DoubleMLAPOS` model, we can numerically equivalent results for the ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef   std err          t  P>|t|     2.5 %    97.5 %\n",
      "d  5.001907  0.066295  75.449677    0.0  4.871972  5.131842\n"
     ]
    }
   ],
   "source": [
    "dml_irm = dml.DoubleMLIRM(**dml_kwargs)\n",
    "dml_irm.set_sample_splitting(all_smpls)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm.fit()\n",
    "\n",
    "print(dml_irm.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training APOS Model\n",
      "       coef   std err           t    P>|t|     2.5 %    97.5 %\n",
      "0  0.038103  0.045984    0.828618  0.40732 -0.052023  0.128229\n",
      "1  5.040010  0.047873  105.278454  0.00000  4.946180  5.133839\n",
      "Evaluate Causal Contrast\n",
      "            coef   std err          t  P>|t|     2.5 %    97.5 %\n",
      "1 vs 0  5.001907  0.066295  75.449677    0.0  4.871972  5.131842\n"
     ]
    }
   ],
   "source": [
    "dml_apos = dml.DoubleMLAPOS(treatment_levels=[0,1], **dml_kwargs)\n",
    "dml_apos.set_sample_splitting(all_smpls)\n",
    "print(\"Training APOS Model\")\n",
    "dml_apos.fit()\n",
    "print(dml_apos.summary)\n",
    "\n",
    "print(\"Evaluate Causal Contrast\")\n",
    "causal_contrast = dml_apos.causal_contrast(reference_levels=[0])\n",
    "print(causal_contrast.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a direct comparison, see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRM Model\n",
      "       coef   std err          t  P>|t|     2.5 %    97.5 %\n",
      "d  5.001907  0.066295  75.449677    0.0  4.871972  5.131842\n",
      "Causal Contrast\n",
      "            coef   std err          t  P>|t|     2.5 %    97.5 %\n",
      "1 vs 0  5.001907  0.066295  75.449677    0.0  4.871972  5.131842\n"
     ]
    }
   ],
   "source": [
    "print(\"IRM Model\")\n",
    "print(dml_irm.summary)\n",
    "print(\"Causal Contrast\")\n",
    "print(causal_contrast.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Treatment Effect on the Treated\n",
    "\n",
    "For the average treatment effect on the treated we can adjust the score in `DoubleMLIRM` model to `score=\"ATTE\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef  std err          t  P>|t|     2.5 %    97.5 %\n",
      "d  5.540549  0.08364  66.242427    0.0  5.376617  5.704482\n"
     ]
    }
   ],
   "source": [
    "dml_irm_atte = dml.DoubleMLIRM(score=\"ATTE\", **dml_kwargs)\n",
    "dml_irm_atte .set_sample_splitting(all_smpls)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm_atte.fit()\n",
    "\n",
    "print(dml_irm_atte.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In to consider weighted effects in the `DoubleMLAPOS` model, we have to specify the correct weight, see [User Guide](https://docs.doubleml.org/stable/guide/heterogeneity.html#weighted-average-treatment-effects).\n",
    "\n",
    "As these weights include the propensity score, we will use the predicted propensity score from the previous `DoubleMLIRM` model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training APOS Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err           t     P>|t|     2.5 %    97.5 %\n",
      "0  0.044929  0.073384    0.612246  0.540375 -0.098901  0.188760\n",
      "1  5.585479  0.039895  140.003045  0.000000  5.507285  5.663672\n",
      "Evaluate Causal Contrast\n",
      "            coef  std err          t  P>|t|     2.5 %    97.5 %\n",
      "1 vs 0  5.540549  0.08364  66.242427    0.0  5.376617  5.704482\n"
     ]
    }
   ],
   "source": [
    "p_hat = df[\"d\"].mean()\n",
    "m_hat = dml_irm_atte.predictions[\"ml_m\"][:, :, 0]\n",
    "\n",
    "weights_dict = {\n",
    "    \"weights\": df[\"d\"] / p_hat,\n",
    "    \"weights_bar\": m_hat / p_hat,\n",
    "}\n",
    "\n",
    "dml_apos_atte = dml.DoubleMLAPOS(treatment_levels=[0,1], weights=weights_dict, **dml_kwargs)\n",
    "dml_apos_atte.set_sample_splitting(all_smpls)\n",
    "print(\"Training APOS Model\")\n",
    "dml_apos_atte.fit()\n",
    "print(dml_apos_atte.summary)\n",
    "\n",
    "print(\"Evaluate Causal Contrast\")\n",
    "causal_contrast_atte = dml_apos_atte.causal_contrast(reference_levels=[0])\n",
    "print(causal_contrast_atte.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point estimates are equal but on closer comparison the standard errors and confidence intervals are larger in the causal contrast example.\n",
    "\n",
    "This is to be expected as `score=ATTE` actually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef  std err          t  P>|t|     2.5 %    97.5 %\n",
      "d  5.540549  0.08364  66.242427    0.0  5.376617  5.704482\n"
     ]
    }
   ],
   "source": [
    "dml_irm_weighted_atte = dml.DoubleMLIRM(score=\"ATE\", weights=weights_dict, **dml_kwargs)\n",
    "dml_irm_weighted_atte .set_sample_splitting(all_smpls)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm_weighted_atte.fit()\n",
    "\n",
    "print(dml_irm_weighted_atte.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRM Model ATTE Score\n",
      "     coef  std err        t  P>|t|   2.5 %  97.5 %\n",
      "d  5.5405   0.0836  66.2424    0.0  5.3766  5.7045\n",
      "IRM Model (Weighted)\n",
      "     coef  std err        t  P>|t|   2.5 %  97.5 %\n",
      "d  5.5405   0.0836  66.2424    0.0  5.3766  5.7045\n",
      "Causal Contrast (Weighted)\n",
      "          coef  std err        t  P>|t|   2.5 %  97.5 %\n",
      "1 vs 0  5.5405   0.0836  66.2424    0.0  5.3766  5.7045\n"
     ]
    }
   ],
   "source": [
    "print(\"IRM Model ATTE Score\")\n",
    "print(dml_irm_atte.summary.round(4))\n",
    "print(\"IRM Model (Weighted)\")\n",
    "print(dml_irm_weighted_atte.summary.round(4))\n",
    "print(\"Causal Contrast (Weighted)\")\n",
    "print(causal_contrast_atte.summary.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "\n",
    "There exist also slight differences with respect to the bounds in the sensitivity analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sensitivity Analysis ==================\n",
      "\n",
      "------------------ Scenario          ------------------\n",
      "Significance Level: level=0.95\n",
      "Sensitivity parameters: cf_y=0.03; cf_d=0.03, rho=1.0\n",
      "\n",
      "------------------ Bounds with CI    ------------------\n",
      "   CI lower  theta lower     theta  theta upper  CI upper\n",
      "d  4.773339     4.890665  5.001907     5.113149  5.217684\n",
      "\n",
      "------------------ Robustness Values ------------------\n",
      "   H_0     RV (%)    RVa (%)\n",
      "d  0.0  72.206256  66.239019\n"
     ]
    }
   ],
   "source": [
    "dml_irm.sensitivity_analysis()\n",
    "print(dml_irm.sensitivity_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sensitivity Analysis ==================\n",
      "\n",
      "------------------ Scenario          ------------------\n",
      "Significance Level: level=0.95\n",
      "Sensitivity parameters: cf_y=0.03; cf_d=0.03, rho=1.0\n",
      "\n",
      "------------------ Bounds with CI    ------------------\n",
      "        CI lower  theta lower     theta  theta upper  CI upper\n",
      "1 vs 0   4.72215     4.844805  5.001907     5.159008   5.26271\n",
      "\n",
      "------------------ Robustness Values ------------------\n",
      "        H_0     RV (%)    RVa (%)\n",
      "1 vs 0  0.0  60.755008  54.175559\n"
     ]
    }
   ],
   "source": [
    "causal_contrast.sensitivity_analysis()\n",
    "print(causal_contrast.sensitivity_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
