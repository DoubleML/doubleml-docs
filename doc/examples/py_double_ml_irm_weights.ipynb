{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the IRM with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_effect(x):\n",
    "    if x[0] <= -0.3:\n",
    "        te = 2.5\n",
    "    elif (x[0] >= 0.2) & (x[1] >= 0.4):\n",
    "        te = 1.5\n",
    "    else:\n",
    "        te = -2\n",
    "    return te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_group_data(n_samples=200, n_w=10, support_size=5):\n",
    "    \"\"\"\n",
    "    Creates a simple synthetic example for group effects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of samples.\n",
    "        Default is ``200``.\n",
    "\n",
    "    n_w : int\n",
    "        Dimension of covariates.\n",
    "        Default is ``10``.\n",
    "\n",
    "    support_size : int\n",
    "        Number of relevant covariates.\n",
    "        Default is ``5``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     data : pd.DataFrame\n",
    "            A data frame.\n",
    "\n",
    "    \"\"\"\n",
    "    # Outcome support\n",
    "    support_w = np.random.choice(np.arange(n_w), size=support_size, replace=False)\n",
    "    coefs_w = np.random.uniform(0, 1, size=support_size)\n",
    "    # Define the function to generate the noise\n",
    "    epsilon_sample = lambda n: np.random.uniform(-1, 1, size=n_samples)\n",
    "    # Treatment support\n",
    "    # Assuming the matrices gamma and beta have the same number of non-zero components\n",
    "    support_t = np.random.choice(np.arange(n_w), size=support_size, replace=False)\n",
    "    coefs_t = np.random.uniform(0, 1, size=support_size)\n",
    "    # Define the function to generate the noise\n",
    "    eta_sample = lambda n: np.random.uniform(-1, 1, size=n_samples)\n",
    "\n",
    "    # Generate controls, covariates, treatments and outcomes\n",
    "    w = np.random.normal(0, 1, size=(n_samples, n_w))\n",
    "    # Group treatment effect\n",
    "    te = np.apply_along_axis(group_effect, axis=1, arr=w)\n",
    "    # Define treatment\n",
    "    log_odds = np.dot(w[:, support_t], coefs_t) + eta_sample(n_samples)\n",
    "    t_sigmoid = 1 / (1 + np.exp(-log_odds))\n",
    "    t = np.array([np.random.binomial(1, p) for p in t_sigmoid])\n",
    "    # Define the outcome\n",
    "    y = te * t + np.dot(w[:, support_w], coefs_w) + epsilon_sample(n_samples)\n",
    "\n",
    "    # Now we build the dataset\n",
    "    y_df = pd.DataFrame({'y': y})\n",
    "    t_df = pd.DataFrame({'t': t})\n",
    "    w_df = pd.DataFrame(data=w, index=np.arange(w.shape[0]),\n",
    "                        columns=[f'w_{i}' for i in range(1, w.shape[1] + 1)])\n",
    "\n",
    "    data = pd.concat([y_df, t_df, w_df], axis=1)\n",
    "    covariates = list(w_df.columns.values)\n",
    "\n",
    "    return data, covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP constants\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "n_w = 10\n",
    "support_size = 5\n",
    "\n",
    "# Create data\n",
    "data, covariates = create_synthetic_group_data(n_samples=n_samples, n_w=n_w, support_size=support_size)\n",
    "data_dml_base = dml.DoubleMLData(data,\n",
    "                                 y_col='y',\n",
    "                                 d_cols='t',\n",
    "                                 x_cols=covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline IRM Model without Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "================== DoubleMLIRM Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['t']\n",
      "Covariates: ['w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6', 'w_7', 'w_8', 'w_9', 'w_10']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: ATE\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_g: RandomForestRegressor(n_estimators=200, random_state=42)\n",
      "Learner ml_m: RandomForestClassifier(n_estimators=200, random_state=42)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_g0 RMSE: [[0.71640709]]\n",
      "Learner ml_g1 RMSE: [[0.89641921]]\n",
      "Learner ml_m RMSE: [[0.48132406]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "t  0.208387  0.122443  1.701908  0.088773 -0.031597  0.448371\n"
     ]
    }
   ],
   "source": [
    "# First stage estimation\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "randomForest_reg = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "randomForest_class = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dml_irm_0 = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5)\n",
    "print(\"Training IRM Model\")\n",
    "print(dml_irm_0.fit(store_predictions=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create weights according to the DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_1, groups_2 = np.zeros_like(data.y.values),np.zeros_like(data.y.values)\n",
    "groups_1[np.where(data[\"w_1\"].values<=-0.3)] = 1\n",
    "groups_2[np.where((data[\"w_1\"].values>=0.2) & (data[\"w_2\"].values>=0.4))] = 1\n",
    "groups_3 = groups_1 + groups_2\n",
    "# weights_1 = groups_1 / groups_1.sum()\n",
    "# weights_2 = groups_2 / groups_2.sum()\n",
    "# weights_3 = groups_3 / groups_3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare weighted ATE to GATE estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef   std err          t         P>|t|    2.5 %    97.5 %\n",
      "t  2.539948  0.127012  19.997749  5.761453e-89  2.29101  2.788886\n",
      "     2.5 %    effect    97.5 %\n",
      "0  2.20386  2.478536  2.753212\n"
     ]
    }
   ],
   "source": [
    "dml_irm = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5,\n",
    "                          weights=groups_1)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm.fit(store_predictions=True)\n",
    "print(dml_irm.summary)\n",
    "print(dml_irm_0.gate(groups=pd.DataFrame(groups_1)).confint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef  std err         t         P>|t|     2.5 %    97.5 %\n",
      "t  1.559241   0.2014  7.741996  9.786780e-15  1.164503  1.953978\n",
      "      2.5 %    effect   97.5 %\n",
      "0  1.069601  1.472045  1.87449\n"
     ]
    }
   ],
   "source": [
    "dml_irm = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5,\n",
    "                          weights=groups_2)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm.fit(store_predictions=True)\n",
    "print(dml_irm.summary)\n",
    "print(dml_irm_0.gate(groups=pd.DataFrame(groups_2)).confint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "t  2.298257  0.107819  21.315881  8.087073e-101  2.086935  2.509578\n",
      "      2.5 %   effect    97.5 %\n",
      "0  1.965647  2.20006  2.434474\n"
     ]
    }
   ],
   "source": [
    "dml_irm = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5,\n",
    "                          weights=groups_3)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm.fit(store_predictions=True)\n",
    "print(dml_irm.summary)\n",
    "print(dml_irm_0.gate(groups=pd.DataFrame(groups_3)).confint())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare weighted ATE to ATTE estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IRM Model\n",
      "       coef  std err         t     P>|t|     2.5 %    97.5 %\n",
      "t  0.230142   0.1477  1.558172  0.119192 -0.059345  0.519629\n",
      "Training IRM Model\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "t  0.069694  0.187706  0.371295  0.710418 -0.298202  0.437591\n"
     ]
    }
   ],
   "source": [
    "dml_irm_atte = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5,\n",
    "                          score=\"ATTE\")\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm_atte.fit(store_predictions=True)\n",
    "print(dml_irm_atte.summary)\n",
    "dml_irm = dml.DoubleMLIRM(data_dml_base,\n",
    "                          ml_g=randomForest_reg,\n",
    "                          ml_m=randomForest_class,\n",
    "                          trimming_threshold=0.01,\n",
    "                          n_folds=5,\n",
    "                          weights=data.t.values)\n",
    "print(\"Training IRM Model\")\n",
    "dml_irm.fit(store_predictions=True)\n",
    "print(dml_irm.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
