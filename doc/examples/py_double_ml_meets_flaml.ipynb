{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoubleML meets FLAML: Comparing AutoML tuning\n",
    "\n",
    "In this notebook we are going to explore how to tune learners with [AUTOML](https://github.com/microsoft/FLAML) in [DoubleML](https://docs.doubleml.org/stable/index.html) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created synthetic data using the [make_plr_CCDDHNR2018](https://docs.doubleml.org/stable/api/generated/doubleml.datasets.make_plr_CCDDHNR2018.html) function, which generates data for a potential outcomes framework with 1000 observations and 50 features. The data generated will have 50 covariates variables, 1 treatment variable and 1 outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958780</td>\n",
       "      <td>-0.507249</td>\n",
       "      <td>-1.237299</td>\n",
       "      <td>-0.337038</td>\n",
       "      <td>-0.788422</td>\n",
       "      <td>0.665523</td>\n",
       "      <td>0.678125</td>\n",
       "      <td>0.523511</td>\n",
       "      <td>-0.284777</td>\n",
       "      <td>1.068380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143543</td>\n",
       "      <td>0.921138</td>\n",
       "      <td>0.665548</td>\n",
       "      <td>1.054878</td>\n",
       "      <td>0.189905</td>\n",
       "      <td>0.720578</td>\n",
       "      <td>-0.233471</td>\n",
       "      <td>-0.234903</td>\n",
       "      <td>-0.380769</td>\n",
       "      <td>-1.175313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.087473</td>\n",
       "      <td>-1.130447</td>\n",
       "      <td>0.217536</td>\n",
       "      <td>1.159132</td>\n",
       "      <td>0.127548</td>\n",
       "      <td>0.212890</td>\n",
       "      <td>-0.269660</td>\n",
       "      <td>-0.345525</td>\n",
       "      <td>-0.839233</td>\n",
       "      <td>0.753701</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.894524</td>\n",
       "      <td>-0.906226</td>\n",
       "      <td>-1.606975</td>\n",
       "      <td>-0.064347</td>\n",
       "      <td>-0.114221</td>\n",
       "      <td>-0.440485</td>\n",
       "      <td>-0.636874</td>\n",
       "      <td>-0.587217</td>\n",
       "      <td>-1.186199</td>\n",
       "      <td>-1.249428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068261</td>\n",
       "      <td>-1.063256</td>\n",
       "      <td>-0.736680</td>\n",
       "      <td>-1.522021</td>\n",
       "      <td>-1.323320</td>\n",
       "      <td>-0.698194</td>\n",
       "      <td>-0.727295</td>\n",
       "      <td>-1.579768</td>\n",
       "      <td>-1.694986</td>\n",
       "      <td>-1.289432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885460</td>\n",
       "      <td>-0.930117</td>\n",
       "      <td>0.798309</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>1.833759</td>\n",
       "      <td>2.176640</td>\n",
       "      <td>1.375478</td>\n",
       "      <td>0.615388</td>\n",
       "      <td>0.109074</td>\n",
       "      <td>-0.324468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.747301</td>\n",
       "      <td>1.280251</td>\n",
       "      <td>1.550265</td>\n",
       "      <td>0.945750</td>\n",
       "      <td>0.341581</td>\n",
       "      <td>-0.217725</td>\n",
       "      <td>0.228431</td>\n",
       "      <td>-0.370202</td>\n",
       "      <td>-0.153972</td>\n",
       "      <td>0.265725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435378</td>\n",
       "      <td>0.474580</td>\n",
       "      <td>1.246745</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>-0.044084</td>\n",
       "      <td>-0.403426</td>\n",
       "      <td>0.139609</td>\n",
       "      <td>1.077118</td>\n",
       "      <td>2.470187</td>\n",
       "      <td>2.178118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.193777</td>\n",
       "      <td>0.535780</td>\n",
       "      <td>0.396372</td>\n",
       "      <td>1.069551</td>\n",
       "      <td>1.078034</td>\n",
       "      <td>0.928753</td>\n",
       "      <td>-0.737033</td>\n",
       "      <td>-0.784358</td>\n",
       "      <td>-0.684771</td>\n",
       "      <td>0.346732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519718</td>\n",
       "      <td>-1.189992</td>\n",
       "      <td>-0.800305</td>\n",
       "      <td>-0.582279</td>\n",
       "      <td>-0.385156</td>\n",
       "      <td>0.063406</td>\n",
       "      <td>-0.570224</td>\n",
       "      <td>0.270637</td>\n",
       "      <td>-1.056063</td>\n",
       "      <td>-0.723587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0 -0.958780 -0.507249 -1.237299 -0.337038 -0.788422  0.665523  0.678125   \n",
       "1 -2.087473 -1.130447  0.217536  1.159132  0.127548  0.212890 -0.269660   \n",
       "2  0.068261 -1.063256 -0.736680 -1.522021 -1.323320 -0.698194 -0.727295   \n",
       "3  1.747301  1.280251  1.550265  0.945750  0.341581 -0.217725  0.228431   \n",
       "4 -0.193777  0.535780  0.396372  1.069551  1.078034  0.928753 -0.737033   \n",
       "\n",
       "         X8        X9       X10  ...       X43       X44       X45       X46  \\\n",
       "0  0.523511 -0.284777  1.068380  ... -0.143543  0.921138  0.665548  1.054878   \n",
       "1 -0.345525 -0.839233  0.753701  ... -1.894524 -0.906226 -1.606975 -0.064347   \n",
       "2 -1.579768 -1.694986 -1.289432  ... -0.885460 -0.930117  0.798309  0.937743   \n",
       "3 -0.370202 -0.153972  0.265725  ... -0.435378  0.474580  1.246745  0.721851   \n",
       "4 -0.784358 -0.684771  0.346732  ... -0.519718 -1.189992 -0.800305 -0.582279   \n",
       "\n",
       "        X47       X48       X49       X50         y         d  \n",
       "0  0.189905  0.720578 -0.233471 -0.234903 -0.380769 -1.175313  \n",
       "1 -0.114221 -0.440485 -0.636874 -0.587217 -1.186199 -1.249428  \n",
       "2  1.833759  2.176640  1.375478  0.615388  0.109074 -0.324468  \n",
       "3 -0.044084 -0.403426  0.139609  1.077118  2.470187  2.178118  \n",
       "4 -0.385156  0.063406 -0.570224  0.270637 -1.056063 -0.723587  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018\n",
    "import doubleml as dml\n",
    "from flaml import AutoML\n",
    "\n",
    "# Generate synthetic data\n",
    "data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=1000, dim_x=50, return_type=\"DataFrame\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Tuning with FLAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we manually tune two [XGBoost](https://xgboost.readthedocs.io/en/stable/) models using FLAML for a [partially linear regression](https://docs.doubleml.org/stable/guide/models.html#partially-linear-regression-model-plr) setup. This means, we implement the tuning with `FLAML` for the nuisance estimation manually. Once the tuning has been completed, we pass the learners to `DoubleML`.\n",
    "\n",
    "### Step 1: Initialize and Train the AutoML Models:\n",
    "\n",
    "We use FLAML to automatically tune two separate [XGBoost](https://xgboost.readthedocs.io/en/stable/) models:\n",
    "\n",
    "• Outcome Model ($ml_\\ell$): This model predicts the outcome variable y. We configured the FLAML AutoML with a time budget of 120 seconds, using XGBoost as the estimator and rmse as the performance metric.\n",
    "\n",
    "• Treatment Model (ml_m): This model predicts the treatment variable d. Similarly, we set the time budget to 120 seconds, used XGBoost, and optimized for rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AutoML for outcome model (ml_l): Predict Y based on X\n",
    "automl_l = AutoML()\n",
    "settings_l = {\n",
    "    \"time_budget\": 120,\n",
    "    \"metric\": 'rmse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "automl_l.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"y\"].values, verbose=2, **settings_l)\n",
    "\n",
    "# Initialize AutoML for treatment model (ml_m): Predict D based on X\n",
    "automl_m = AutoML()\n",
    "settings_m = {\n",
    "    \"time_budget\": 120,\n",
    "    \"metric\": 'rmse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "automl_m.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"d\"].values, verbose=2, **settings_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluate the Tuned Models \n",
    "\n",
    "We can evaluate the loss as reported by `FLAML`. For more details, we refer to the [FLAML documentation](https://microsoft.github.io/FLAML/docs/Getting-Started)\n",
    "\n",
    "• `rmse_oos_ml_m` represents the out-of-sample RMSE for the treatment model.\n",
    "\n",
    "• `rmse_oos_ml_l` represents the out-of-sample RMSE for the outcome model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Overfitting: Compare in-sample (train), out-of-sample (test) MSE\n",
    "# ml_m\n",
    "rmse_oos_ml_m = automl_m.best_loss\n",
    "rmse_oos_ml_l = automl_l.best_loss\n",
    "print(\"rmse_oos_ml_m:\",rmse_oos_ml_m)\n",
    "print(\"rmse_oos_ml_m:\",rmse_oos_ml_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and Fit DoubleML Model\n",
    "\n",
    "We create a [DoubleMLData](https://docs.doubleml.org/stable/guide/data_backend.html) object with the dataset, specifying $y$ as the outcome variable and $d$ as the treatment variable. We then initialize a `DoubleMLPLR` model using the tuned `FLAML` models for both the treatment and outcome components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DoubleMLData object with the evaluation set\n",
    "obj_dml_data = dml.DoubleMLData(data, \"y\", \"d\")\n",
    "\n",
    "# Initialize DoubleMLPLR with the trained models from flaml\n",
    "obj_dml_plr_manual_tuned = dml.DoubleMLPLR(obj_dml_data, ml_m=automl_m.model.estimator,\n",
    "                                           ml_l=automl_l.model.estimator)\n",
    "\n",
    "# Fit the DoubleMLPLR model\n",
    "obj_dml_plr_manual_tuned.fit(store_predictions=True)\n",
    "\n",
    "print(obj_dml_plr_manual_tuned.summary)\n",
    "manual_tuned_summary = obj_dml_plr_manual_tuned.summary\n",
    "print(manual_tuned_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `DoubleML`'s built-in learner evaluation, which is based on the cross-fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate learners using evaluate_learners() (MSE for all nuisance components)\n",
    "rmse_dml_ml_l = obj_dml_plr_manual_tuned.evaluate_learners()['ml_l'][0]\n",
    "rmse_dml_ml_m = obj_dml_plr_manual_tuned.evaluate_learners()['ml_m'][0]\n",
    "\n",
    "# Print results\n",
    "print(\"RMLSE evaluated by DoubleML (ml_l):\", rmse_dml_ml_l)\n",
    "print(\"RMSE evaluated by DoubleML (ml_m):\", rmse_dml_ml_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Model Tuning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of externally tuning the `FLAML` learners, it is also possible to tune the AutoML learners internally. To do so, we have to define custom classes for integrating `FLAML` with `DoubleML`. The tuning will be automatically be started when calling `DoubleML`'s `fit()` method. This approach does not make it necessary to manually specify the learning tasks.\n",
    "\n",
    "\n",
    "### Step 1: Designing Custom FLAML Models for Double Machine Learning\n",
    "\n",
    "In this section, we define custom classes for integrating FLAML (Fast Lightweight AutoML) with Double Machine Learning (DML). These classes are designed to facilitate automated machine learning model tuning for both regression and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class FlamlRegressorDoubleML:\n",
    "    _estimator_type = 'regressor'\n",
    "\n",
    "    def __init__(self, time, estimator_list, metric, *args, **kwargs):\n",
    "        self.auto_ml = AutoML(*args, **kwargs)\n",
    "        self.time = time\n",
    "        self.estimator_list = estimator_list\n",
    "        self.metric = metric\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.auto_ml.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        dict = self.auto_ml.get_params(deep)\n",
    "        dict[\"time\"] = self.time\n",
    "        dict[\"estimator_list\"] = self.estimator_list\n",
    "        dict[\"metric\"] = self.metric\n",
    "        return dict\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.auto_ml.fit(X, y, task=\"regression\", time_budget=self.time, estimator_list=self.estimator_list, metric=self.metric, verbose=False)\n",
    "        self.tuned_model = self.auto_ml.model.estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        preds = self.tuned_model.predict(x)\n",
    "        return preds\n",
    "        \n",
    "class FlamlClassifierDoubleML:\n",
    "    _estimator_type = 'classifier'\n",
    "\n",
    "    def __init__(self, time, estimator_list, metric, *args, **kwargs):\n",
    "        self.auto_ml = AutoML(*args, **kwargs)\n",
    "        self.time = time\n",
    "        self.estimator_list = estimator_list\n",
    "        self.metric = metric\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.auto_ml.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        dict = self.auto_ml.get_params(deep)\n",
    "        dict[\"time\"] = self.time\n",
    "        dict[\"estimator_list\"] = self.estimator_list\n",
    "        dict[\"metric\"] = self.metric\n",
    "        return dict\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.auto_ml.fit(X, y, task=\"classification\", time_budget=self.time, estimator_list=self.estimator_list, metric=self.metric, verbose=False)\n",
    "        self.tuned_model = self.auto_ml.model.estimator\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        preds = self.tuned_model.predict_proba(x)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Using Custom FLAML Models when calling `DoubleML`'s `fit()` Method\n",
    "\n",
    "We integrate the custom `FLAML`-based models `FlamlRegressorDoubleML` into the Double Machine Learning (DML) framework. The steps involve defining the `FLAML` regressors, setting up the `DoubleMLPLR` object, and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FlamlRegressorDoubleML\n",
    "ml_l = FlamlRegressorDoubleML(time=120, estimator_list=['xgboost'], metric='rmse')\n",
    "ml_m = FlamlRegressorDoubleML(time=120, estimator_list=['xgboost'], metric='rmse')\n",
    "\n",
    "# Create DoubleMLPLR object using the new regressors\n",
    "dml_plr_obj_api_tuned = dml.DoubleMLPLR(obj_dml_data, ml_m, ml_l)\n",
    "\n",
    "# Fit the DoubleMLPLR model\n",
    "dml_plr_obj_api_tuned.fit(store_predictions=True)\n",
    "\n",
    "#Retrieve the summary for API Tuned Models\n",
    "api_tuned_summary = dml_plr_obj_api_tuned.summary\n",
    "\n",
    "# Print the summary\n",
    "print(dml_plr_obj_api_tuned.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Dummy Models and Untuned AutoML Learners\n",
    "\n",
    "\n",
    "### Dummy Learners\n",
    "\n",
    "As a comparison, we can use dummy `sklearn`'s  `DummyRegressor` learners\n",
    "\n",
    "• `ml_l_dummy`: A dummy regressor for the outcome model, which predicts the mean value of the outcome.\n",
    "\n",
    "• `ml_m_dummy`: A dummy regressor for the treatment model, also predicting the mean value.\n",
    "\n",
    "These dummy models are used to create a `DoubleMLPLR` object, which was then fit to the data. We retrieve and stored the summary of this model to compare with other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Initialize and fit dummy models\n",
    "ml_l_dummy = DummyRegressor(strategy='mean')\n",
    "ml_m_dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Create DoubleMLPLR object using dummy regressors\n",
    "dml_plr_obj_dummy = dml.DoubleMLPLR(obj_dml_data, ml_m_dummy, ml_l_dummy)\n",
    "dml_plr_obj_dummy.fit(store_predictions=True)\n",
    "\n",
    "# Retrieve the summary for dummy models\n",
    "dummy_summary = dml_plr_obj_dummy.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Untuned Models\n",
    "\n",
    "We set up AutoML models with minimal tuning for both the outcome and treatment variables. This process allows us to compare the performance of untuned models against those that have been manually or API-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Untuned\n",
    "automl_untuned_l = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 0.01,\n",
    "    \"metric\": 'mse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "\n",
    "automl_untuned_l.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"y\"].values, verbose=0, **settings)\n",
    "\n",
    "automl_untuned_m = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 0.01,\n",
    "    \"metric\": 'mse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "\n",
    "automl_untuned_m.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"d\"].values, verbose=0, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DoubleMLPLR with Untuned AutoML Models\n",
    "\n",
    "Here, we create a `DoubleMLPLR` object using the untuned AutoML models for the outcome and treatment regressions. We then fit the `DoubleMLPLR` model and retrieve the summary of the results. This section allows us to evaluate the performance of the untuned AutoML models in the context of DoubleML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DoubleMLPLR object using AutoML models\n",
    "dml_plr_obj_untuned_automl = dml.DoubleMLPLR(obj_dml_data, automl_untuned_l.model.estimator, automl_untuned_m.model.estimator)\n",
    "untuned_automl_summary = dml_plr_obj_untuned_automl.fit(store_predictions=True).summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We combine the summaries from various models: manually tuned FLAML models, API-tuned FLAML models, untuned AutoML models, and dummy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine summaries for comparison\n",
    "summary = pd.concat([manual_tuned_summary ,api_tuned_summary, untuned_automl_summary, dummy_summary],\n",
    "                    keys=['FLAML Manual Tuned', 'FLAML API Tuned', 'AutoML Untuned', 'Dummy'])\n",
    "summary.index.names = ['Model Type', 'Metric']\n",
    "\n",
    "# Print the summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Coefficients and 95% Confidence Intervals\n",
    "\n",
    "This section generates a plot comparing the coefficients and 95% confidence intervals for each model type. The plot helps visualize the differences in the estimated coefficients and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the summary DataFrames\n",
    "print(\"Manual Tuned Summary:\")\n",
    "print(manual_tuned_summary.head())\n",
    "\n",
    "print(\"API Tuned Summary:\")\n",
    "print(api_tuned_summary.head())\n",
    "\n",
    "print(\"Untuned Summary:\")\n",
    "print(untuned_automl_summary.head())\n",
    "\n",
    "print(\"Dummy Summary:\")\n",
    "print(dummy_summary.head())\n",
    "\n",
    "# Extract model labels and coefficient values\n",
    "model_labels = summary.index.get_level_values('Model Type')\n",
    "coef_values = summary['coef'].values\n",
    "\n",
    "# Calculate errors\n",
    "errors = np.full((2, len(coef_values)), np.nan)\n",
    "errors[0, :] = summary['coef'] - summary['2.5 %']\n",
    "errors[1, :] = summary['97.5 %'] - summary['coef']\n",
    "\n",
    "# Plot Coefficients and 95% Confidence Intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(model_labels, coef_values, fmt='o', yerr=errors, capsize=5)\n",
    "plt.axhline(0.5, color='red', linestyle='--')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Coefficients and 95%-CI')\n",
    "plt.title('Comparison of Coefficients and 95% Confidence Intervals')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare Metrics for Nuisance Estimation\n",
    "\n",
    "In this section, we compare metrics for different models and plot a bar chart to visualize the differences in their performance. We also save the comparison results to a file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(dml_obj):\n",
    "    summary_df = dml_obj.summary\n",
    "    print(\"Summary DataFrame columns:\", summary_df.columns)\n",
    "    print(\"Summary DataFrame index:\", summary_df.index)\n",
    "      \n",
    "    scores = summary_df.loc['d']\n",
    "    return scores\n",
    "\n",
    "# Calculate and store scores for comparison\n",
    "scores = {\n",
    "    \"FLAML Manual Tuned\": obj_dml_plr_manual_tuned.summary.loc['d'],\n",
    "    \"FLAML API Tuned\": dml_plr_obj_api_tuned.summary.loc['d'],\n",
    "    \"AutoML Untuned\": dml_plr_obj_untuned_automl.summary.loc['d'],\n",
    "    \"Dummy\": dml_plr_obj_dummy.summary.loc['d']\n",
    "}\n",
    "\n",
    "# Convert the scores dictionary to a DataFrame for plotting\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "\n",
    "# Plot MSE for l_of_X and m_of_X separately\n",
    "scores_df['coef'].plot(kind=\"bar\", title=\"MSE for l_of_X\")\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "scores_df['std err'].plot(kind=\"bar\", title=\"MSE for m_of_X\")\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- **Coefficient Values**: The coefficients for the `FLAML Manual Tuned` and `FLAML API Tuned` models are quite similar, with the API-tuned model having a slightly higher coefficient. Both are lower compared to the `AutoML Untuned` and `Dummy` models.\n",
    "- **Untuned AutoML Models**: The `AutoML Untuned` models yield a higher coefficient compared to the manually tuned FLAML models, indicating that the automated process of model tuning in AutoML may have overestimated the effect. The `Dummy` model has the highest coefficient, suggesting it could be overfitting or has a higher baseline value.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- The **FLAML Manual Tuned** and **FLAML API Tuned** models provide similar results with coefficients close to 0.5, suggesting robust performance within their tuned configurations.\n",
    "- The **AutoML Untuned** models offer higher coefficient values, indicating that even though they are untuned, they still provide a noticeable increase in coefficient compared to the tuned FLAML models.\n",
    "- The **Dummy** model, having the highest coefficient, shows the largest discrepancy. This reflects the fact, that the learner is not actually learning any meaningful relationship between the features and the outcome/treatment variable. \n",
    "\n",
    "Overall, the manually tuned FLAML models and the API-tuned FLAML models show good alignment with the expectations, while the untuned and dummy models present larger coefficients which may suggest the need for further tuning or validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
