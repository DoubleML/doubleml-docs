{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoubleML meets FLAML: Comparing AutoML tuning\n",
    "\n",
    "In this notebook we are going to explore how to tune learners with [AUTOML](https://github.com/microsoft/FLAML) in [DoubleML](https://docs.doubleml.org/stable/index.html) framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created synthetic data using the [make_plr_CCDDHNR2018](https://docs.doubleml.org/stable/api/generated/doubleml.datasets.make_plr_CCDDHNR2018.html) function, which generates data for a potential outcomes framework with 1000 observations and 50 features. The data generated will have 50 covariates variables, 1 treatment variable and 1 outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018\n",
    "import doubleml as dml\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic data\n",
    "data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=1000, dim_x=50, return_type=\"DataFrame\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Tuning with FLAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we manually tune two [XGBoost](https://xgboost.readthedocs.io/en/stable/) models using FLAML for a [partially linear regression](https://docs.doubleml.org/stable/guide/models.html#partially-linear-regression-model-plr) setup. This means, we implement the tuning with `FLAML` for the nuisance estimation manually. Once the tuning has been completed, we pass the learners to `DoubleML`.\n",
    "\n",
    "### Step 1: Initialize and Train the AutoML Models:\n",
    "\n",
    "We use FLAML to automatically tune two separate [XGBoost](https://xgboost.readthedocs.io/en/stable/) models:\n",
    "\n",
    "• Outcome Model ($ml_\\ell$): This model predicts the outcome variable y. We configured the FLAML AutoML with a time budget of 120 seconds, using XGBoost as the estimator and rmse as the performance metric.\n",
    "\n",
    "• Treatment Model (ml_m): This model predicts the treatment variable d. Similarly, we set the time budget to 120 seconds, used XGBoost, and optimized for rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     12\u001b[0m automl_m \u001b[38;5;241m=\u001b[39m AutoML()\n\u001b[0;32m     13\u001b[0m settings_m \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_budget\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m120\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m }\n\u001b[1;32m---> 19\u001b[0m automl_m\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues, y_train\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_m)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:1929\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[1;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, **fit_kwargs)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search()\n\u001b[0;32m   1930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_estimator:\n\u001b[0;32m   1931\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit succeeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:2483\u001b[0m, in \u001b[0;36mAutoML._search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2481\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_config \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39minit_config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39minit_config \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m-> 2483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_sequential()\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\automl.py:2319\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2313\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[0;32m   2314\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2315\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2316\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m   2317\u001b[0m         )\n\u001b[0;32m   2318\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 2319\u001b[0m analysis \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2320\u001b[0m     search_state\u001b[38;5;241m.\u001b[39mtraining_function,\n\u001b[0;32m   2321\u001b[0m     search_alg\u001b[38;5;241m=\u001b[39msearch_state\u001b[38;5;241m.\u001b[39msearch_alg,\n\u001b[0;32m   2322\u001b[0m     time_budget_s\u001b[38;5;241m=\u001b[39mtime_budget_s,\n\u001b[0;32m   2323\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   2324\u001b[0m     use_ray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2325\u001b[0m     use_spark\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2326\u001b[0m )\n\u001b[0;32m   2327\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[0;32m   2328\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\tune\\tune.py:814\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, **ray_args)\u001b[0m\n\u001b[0;32m    812\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[1;32m--> 814\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluation_function(trial_to_run\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\state.py:304\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[1;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m-\u001b[39m state\u001b[38;5;241m.\u001b[39mtime_from_start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sample_size \u001b[38;5;241m/\u001b[39m state\u001b[38;5;241m.\u001b[39mdata_size[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    296\u001b[0m )\n\u001b[0;32m    298\u001b[0m (\n\u001b[0;32m    299\u001b[0m     trained_estimator,\n\u001b[0;32m    300\u001b[0m     val_loss,\n\u001b[0;32m    301\u001b[0m     metric_for_logging,\n\u001b[0;32m    302\u001b[0m     _,\n\u001b[0;32m    303\u001b[0m     pred_time,\n\u001b[1;32m--> 304\u001b[0m ) \u001b[38;5;241m=\u001b[39m compute_estimator(\n\u001b[0;32m    305\u001b[0m     sampled_X_train,\n\u001b[0;32m    306\u001b[0m     sampled_y_train,\n\u001b[0;32m    307\u001b[0m     state\u001b[38;5;241m.\u001b[39mX_val,\n\u001b[0;32m    308\u001b[0m     state\u001b[38;5;241m.\u001b[39my_val,\n\u001b[0;32m    309\u001b[0m     state\u001b[38;5;241m.\u001b[39mweight_val,\n\u001b[0;32m    310\u001b[0m     state\u001b[38;5;241m.\u001b[39mgroups_val,\n\u001b[0;32m    311\u001b[0m     state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;28;01mif\u001b[39;00m budget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(budget, state\u001b[38;5;241m.\u001b[39mtrain_time_limit \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf),\n\u001b[0;32m    312\u001b[0m     state\u001b[38;5;241m.\u001b[39mkf,\n\u001b[0;32m    313\u001b[0m     config,\n\u001b[0;32m    314\u001b[0m     state\u001b[38;5;241m.\u001b[39mtask,\n\u001b[0;32m    315\u001b[0m     estimator,\n\u001b[0;32m    316\u001b[0m     state\u001b[38;5;241m.\u001b[39meval_method,\n\u001b[0;32m    317\u001b[0m     state\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[0;32m    318\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[0;32m    319\u001b[0m     state\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    320\u001b[0m     state\u001b[38;5;241m.\u001b[39mlearner_classes\u001b[38;5;241m.\u001b[39mget(estimator),\n\u001b[0;32m    321\u001b[0m     state\u001b[38;5;241m.\u001b[39mcv_score_agg_func,\n\u001b[0;32m    322\u001b[0m     state\u001b[38;5;241m.\u001b[39mlog_training_metric,\n\u001b[0;32m    323\u001b[0m     this_estimator_kwargs,\n\u001b[0;32m    324\u001b[0m     state\u001b[38;5;241m.\u001b[39mfree_mem_ratio,\n\u001b[0;32m    325\u001b[0m )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[0;32m    327\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\ml.py:369\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[1;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    351\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[0;32m    352\u001b[0m         config_dic,\n\u001b[0;32m    353\u001b[0m         estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    367\u001b[0m     )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate_model_CV(\n\u001b[0;32m    370\u001b[0m         config_dic,\n\u001b[0;32m    371\u001b[0m         estimator,\n\u001b[0;32m    372\u001b[0m         X_train,\n\u001b[0;32m    373\u001b[0m         y_train,\n\u001b[0;32m    374\u001b[0m         budget,\n\u001b[0;32m    375\u001b[0m         kf,\n\u001b[0;32m    376\u001b[0m         eval_metric,\n\u001b[0;32m    377\u001b[0m         best_val_loss,\n\u001b[0;32m    378\u001b[0m         cv_score_agg_func,\n\u001b[0;32m    379\u001b[0m         log_training_metric\u001b[38;5;241m=\u001b[39mlog_training_metric,\n\u001b[0;32m    380\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    381\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    382\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, TransformersEstimator):\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val\u001b[39m\u001b[38;5;124m\"\u001b[39m], fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\task\\generic_task.py:740\u001b[0m, in \u001b[0;36mGenericTask.evaluate_model_CV\u001b[1;34m(self, config, estimator, X_train_all, y_train_all, budget, kf, eval_metric, best_val_loss, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    737\u001b[0m         groups_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m estimator\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m--> 740\u001b[0m val_loss_i, metric_i, train_time_i, pred_time_i \u001b[38;5;241m=\u001b[39m get_val_loss(\n\u001b[0;32m    741\u001b[0m     config,\n\u001b[0;32m    742\u001b[0m     estimator,\n\u001b[0;32m    743\u001b[0m     X_train,\n\u001b[0;32m    744\u001b[0m     y_train,\n\u001b[0;32m    745\u001b[0m     X_val,\n\u001b[0;32m    746\u001b[0m     y_val,\n\u001b[0;32m    747\u001b[0m     weight_val,\n\u001b[0;32m    748\u001b[0m     groups_val,\n\u001b[0;32m    749\u001b[0m     eval_metric,\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    751\u001b[0m     labels,\n\u001b[0;32m    752\u001b[0m     budget_per_train,\n\u001b[0;32m    753\u001b[0m     log_training_metric\u001b[38;5;241m=\u001b[39mlog_training_metric,\n\u001b[0;32m    754\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m    755\u001b[0m     free_mem_ratio\u001b[38;5;241m=\u001b[39mfree_mem_ratio,\n\u001b[0;32m    756\u001b[0m )\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metric_i, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m metric_i\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m metric_i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\ml.py:494\u001b[0m, in \u001b[0;36mget_val_loss\u001b[1;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, task, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[0;32m    489\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['groups_val'] = groups_val\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['X_val'] = X_val\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['y_val'] = y_val\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, budget\u001b[38;5;241m=\u001b[39mbudget, free_mem_ratio\u001b[38;5;241m=\u001b[39mfree_mem_ratio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    495\u001b[0m val_loss, metric_for_logging, pred_time, _ \u001b[38;5;241m=\u001b[39m _eval_estimator(\n\u001b[0;32m    496\u001b[0m     config,\n\u001b[0;32m    497\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m     fit_kwargs,\n\u001b[0;32m    509\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\model.py:1667\u001b[0m, in \u001b[0;36mXGBoostSklearnEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_method\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1666\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu_per_trial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, budget, free_mem_ratio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\model.py:1422\u001b[0m, in \u001b[0;36mLGBMEstimator.fit\u001b[1;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m         callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1422\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X_train, y_train, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\flaml\\automl\\model.py:232\u001b[0m, in \u001b[0;36mBaseEstimator._fit\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# xgboost 1.6 doesn't display all the params in the model str\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaml.automl.model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit started with params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[0;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaml.automl.model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m (\n\u001b[0;32m   1082\u001b[0m     model,\n\u001b[0;32m   1083\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1089\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1091\u001b[0m     params,\n\u001b[0;32m   1092\u001b[0m     train_dmatrix,\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1094\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1095\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1096\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1097\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1098\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1099\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1100\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1101\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1102\u001b[0m )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bachp\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2052\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2053\u001b[0m         )\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize AutoML for outcome model (ml_l): Predict Y based on X\n",
    "automl_l = AutoML()\n",
    "settings_l = {\n",
    "    \"time_budget\": 120,\n",
    "    \"metric\": 'rmse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "automl_l.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"y\"].values, verbose=2, **settings_l)\n",
    "\n",
    "# Initialize AutoML for treatment model (ml_m): Predict D based on X\n",
    "automl_m = AutoML()\n",
    "settings_m = {\n",
    "    \"time_budget\": 120,\n",
    "    \"metric\": 'rmse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "automl_m.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"d\"].values, verbose=2, **settings_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluate the Tuned Models \n",
    "\n",
    "We can evaluate the loss as reported by `FLAML`. For more details, we refer to the [FLAML documentation](https://microsoft.github.io/FLAML/docs/Getting-Started)\n",
    "\n",
    "• `rmse_oos_ml_m` represents the out-of-sample RMSE for the treatment model.\n",
    "\n",
    "• `rmse_oos_ml_l` represents the out-of-sample RMSE for the outcome model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Overfitting: Compare in-sample (train), out-of-sample (test) MSE\n",
    "# ml_m\n",
    "rmse_oos_ml_m = automl_m.best_loss\n",
    "rmse_oos_ml_l = automl_l.best_loss\n",
    "print(\"rmse_oos_ml_m:\",rmse_oos_ml_m)\n",
    "print(\"rmse_oos_ml_m:\",rmse_oos_ml_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and Fit DoubleML Model\n",
    "\n",
    "We create a [DoubleMLData](https://docs.doubleml.org/stable/guide/data_backend.html) object with the dataset, specifying $y$ as the outcome variable and $d$ as the treatment variable. We then initialize a `DoubleMLPLR` model using the tuned `FLAML` models for both the treatment and outcome components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DoubleMLData object with the evaluation set\n",
    "obj_dml_data = dml.DoubleMLData(data, \"y\", \"d\")\n",
    "\n",
    "# Initialize DoubleMLPLR with the trained models from flaml\n",
    "obj_dml_plr_manual_tuned = dml.DoubleMLPLR(obj_dml_data, ml_m=automl_m.model.estimator,\n",
    "                                           ml_l=automl_l.model.estimator)\n",
    "\n",
    "# Fit the DoubleMLPLR model\n",
    "obj_dml_plr_manual_tuned.fit(store_predictions=True)\n",
    "\n",
    "print(obj_dml_plr_manual_tuned.summary)\n",
    "manual_tuned_summary = obj_dml_plr_manual_tuned.summary\n",
    "print(manual_tuned_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `DoubleML`'s built-in learner evaluation, which is based on the cross-fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate learners using evaluate_learners() (MSE for all nuisance components)\n",
    "rmse_dml_ml_l = obj_dml_plr_manual_tuned.evaluate_learners()['ml_l'][0]\n",
    "rmse_dml_ml_m = obj_dml_plr_manual_tuned.evaluate_learners()['ml_m'][0]\n",
    "\n",
    "# Print results\n",
    "print(\"RMLSE evaluated by DoubleML (ml_l):\", rmse_dml_ml_l)\n",
    "print(\"RMSE evaluated by DoubleML (ml_m):\", rmse_dml_ml_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Model Tuning Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of externally tuning the `FLAML` learners, it is also possible to tune the AutoML learners internally. To do so, we have to define custom classes for integrating `FLAML` with `DoubleML`. The tuning will be automatically be started when calling `DoubleML`'s `fit()` method. This approach does not make it necessary to manually specify the learning tasks.\n",
    "\n",
    "\n",
    "### Step 1: Designing Custom FLAML Models for Double Machine Learning\n",
    "\n",
    "In this section, we define custom classes for integrating FLAML (Fast Lightweight AutoML) with Double Machine Learning (DML). These classes are designed to facilitate automated machine learning model tuning for both regression and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class FlamlRegressorDoubleML:\n",
    "    _estimator_type = 'regressor'\n",
    "\n",
    "    def __init__(self, time, estimator_list, metric, *args, **kwargs):\n",
    "        self.auto_ml = AutoML(*args, **kwargs)\n",
    "        self.time = time\n",
    "        self.estimator_list = estimator_list\n",
    "        self.metric = metric\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.auto_ml.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        dict = self.auto_ml.get_params(deep)\n",
    "        dict[\"time\"] = self.time\n",
    "        dict[\"estimator_list\"] = self.estimator_list\n",
    "        dict[\"metric\"] = self.metric\n",
    "        return dict\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.auto_ml.fit(X, y, task=\"regression\", time_budget=self.time, estimator_list=self.estimator_list, metric=self.metric, verbose=False)\n",
    "        self.tuned_model = self.auto_ml.model.estimator\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        preds = self.tuned_model.predict(x)\n",
    "        return preds\n",
    "        \n",
    "class FlamlClassifierDoubleML:\n",
    "    _estimator_type = 'classifier'\n",
    "\n",
    "    def __init__(self, time, estimator_list, metric, *args, **kwargs):\n",
    "        self.auto_ml = AutoML(*args, **kwargs)\n",
    "        self.time = time\n",
    "        self.estimator_list = estimator_list\n",
    "        self.metric = metric\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.auto_ml.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        dict = self.auto_ml.get_params(deep)\n",
    "        dict[\"time\"] = self.time\n",
    "        dict[\"estimator_list\"] = self.estimator_list\n",
    "        dict[\"metric\"] = self.metric\n",
    "        return dict\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.auto_ml.fit(X, y, task=\"classification\", time_budget=self.time, estimator_list=self.estimator_list, metric=self.metric, verbose=False)\n",
    "        self.tuned_model = self.auto_ml.model.estimator\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        preds = self.tuned_model.predict_proba(x)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Using Custom FLAML Models when calling `DoubleML`'s `fit()` Method\n",
    "\n",
    "We integrate the custom `FLAML`-based models `FlamlRegressorDoubleML` into the Double Machine Learning (DML) framework. The steps involve defining the `FLAML` regressors, setting up the `DoubleMLPLR` object, and fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FlamlRegressorDoubleML\n",
    "ml_l = FlamlRegressorDoubleML(time=120, estimator_list=['xgboost'], metric='rmse')\n",
    "ml_m = FlamlRegressorDoubleML(time=120, estimator_list=['xgboost'], metric='rmse')\n",
    "\n",
    "# Create DoubleMLPLR object using the new regressors\n",
    "dml_plr_obj_api_tuned = dml.DoubleMLPLR(obj_dml_data, ml_m, ml_l)\n",
    "\n",
    "# Fit the DoubleMLPLR model\n",
    "dml_plr_obj_api_tuned.fit(store_predictions=True)\n",
    "\n",
    "#Retrieve the summary for API Tuned Models\n",
    "api_tuned_summary = dml_plr_obj_api_tuned.summary\n",
    "\n",
    "# Print the summary\n",
    "print(dml_plr_obj_api_tuned.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Dummy Models and Untuned AutoML Learners\n",
    "\n",
    "\n",
    "### Dummy Learners\n",
    "\n",
    "As a comparison, we can use dummy `sklearn`'s  `DummyRegressor` learners\n",
    "\n",
    "• `ml_l_dummy`: A dummy regressor for the outcome model, which predicts the mean value of the outcome.\n",
    "\n",
    "• `ml_m_dummy`: A dummy regressor for the treatment model, also predicting the mean value.\n",
    "\n",
    "These dummy models are used to create a `DoubleMLPLR` object, which was then fit to the data. We retrieve and stored the summary of this model to compare with other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Initialize and fit dummy models\n",
    "ml_l_dummy = DummyRegressor(strategy='mean')\n",
    "ml_m_dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Create DoubleMLPLR object using dummy regressors\n",
    "dml_plr_obj_dummy = dml.DoubleMLPLR(obj_dml_data, ml_m_dummy, ml_l_dummy)\n",
    "dml_plr_obj_dummy.fit(store_predictions=True)\n",
    "\n",
    "# Retrieve the summary for dummy models\n",
    "dummy_summary = dml_plr_obj_dummy.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML Untuned Models\n",
    "\n",
    "We set up AutoML models with minimal tuning for both the outcome and treatment variables. This process allows us to compare the performance of untuned models against those that have been manually or API-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Untuned\n",
    "automl_untuned_l = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 0.01,\n",
    "    \"metric\": 'mse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "\n",
    "automl_untuned_l.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"y\"].values, verbose=0, **settings)\n",
    "\n",
    "automl_untuned_m = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 0.01,\n",
    "    \"metric\": 'mse',\n",
    "    \"estimator_list\": ['xgboost'],\n",
    "    \"task\": 'regression',\n",
    "}\n",
    "\n",
    "automl_untuned_m.fit(X_train=data.drop(columns=[\"y\", \"d\"]).values, y_train=data[\"d\"].values, verbose=0, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DoubleMLPLR with Untuned AutoML Models\n",
    "\n",
    "Here, we create a `DoubleMLPLR` object using the untuned AutoML models for the outcome and treatment regressions. We then fit the `DoubleMLPLR` model and retrieve the summary of the results. This section allows us to evaluate the performance of the untuned AutoML models in the context of DoubleML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DoubleMLPLR object using AutoML models\n",
    "dml_plr_obj_untuned_automl = dml.DoubleMLPLR(obj_dml_data, automl_untuned_l.model.estimator, automl_untuned_m.model.estimator)\n",
    "untuned_automl_summary = dml_plr_obj_untuned_automl.fit(store_predictions=True).summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We combine the summaries from various models: manually tuned FLAML models, API-tuned FLAML models, untuned AutoML models, and dummy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine summaries for comparison\n",
    "summary = pd.concat([manual_tuned_summary ,api_tuned_summary, untuned_automl_summary, dummy_summary],\n",
    "                    keys=['FLAML Manual Tuned', 'FLAML API Tuned', 'AutoML Untuned', 'Dummy'])\n",
    "summary.index.names = ['Model Type', 'Metric']\n",
    "\n",
    "# Print the summary\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Coefficients and 95% Confidence Intervals\n",
    "\n",
    "This section generates a plot comparing the coefficients and 95% confidence intervals for each model type. The plot helps visualize the differences in the estimated coefficients and their uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the summary DataFrames\n",
    "print(\"Manual Tuned Summary:\")\n",
    "print(manual_tuned_summary.head())\n",
    "\n",
    "print(\"API Tuned Summary:\")\n",
    "print(api_tuned_summary.head())\n",
    "\n",
    "print(\"Untuned Summary:\")\n",
    "print(untuned_automl_summary.head())\n",
    "\n",
    "print(\"Dummy Summary:\")\n",
    "print(dummy_summary.head())\n",
    "\n",
    "# Extract model labels and coefficient values\n",
    "model_labels = summary.index.get_level_values('Model Type')\n",
    "coef_values = summary['coef'].values\n",
    "\n",
    "# Calculate errors\n",
    "errors = np.full((2, len(coef_values)), np.nan)\n",
    "errors[0, :] = summary['coef'] - summary['2.5 %']\n",
    "errors[1, :] = summary['97.5 %'] - summary['coef']\n",
    "\n",
    "# Plot Coefficients and 95% Confidence Intervals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(model_labels, coef_values, fmt='o', yerr=errors, capsize=5)\n",
    "plt.axhline(0.5, color='red', linestyle='--')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Coefficients and 95%-CI')\n",
    "plt.title('Comparison of Coefficients and 95% Confidence Intervals')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare Metrics for Nuisance Estimation\n",
    "\n",
    "In this section, we compare metrics for different models and plot a bar chart to visualize the differences in their performance. We also save the comparison results to a file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(dml_obj):\n",
    "    summary_df = dml_obj.summary\n",
    "    print(\"Summary DataFrame columns:\", summary_df.columns)\n",
    "    print(\"Summary DataFrame index:\", summary_df.index)\n",
    "      \n",
    "    scores = summary_df.loc['d']\n",
    "    return scores\n",
    "\n",
    "# Calculate and store scores for comparison\n",
    "scores = {\n",
    "    \"FLAML Manual Tuned\": obj_dml_plr_manual_tuned.summary.loc['d'],\n",
    "    \"FLAML API Tuned\": dml_plr_obj_api_tuned.summary.loc['d'],\n",
    "    \"AutoML Untuned\": dml_plr_obj_untuned_automl.summary.loc['d'],\n",
    "    \"Dummy\": dml_plr_obj_dummy.summary.loc['d']\n",
    "}\n",
    "\n",
    "# Convert the scores dictionary to a DataFrame for plotting\n",
    "scores_df = pd.DataFrame(scores).T\n",
    "\n",
    "# Plot MSE for l_of_X and m_of_X separately\n",
    "scores_df['coef'].plot(kind=\"bar\", title=\"MSE for l_of_X\")\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "scores_df['std err'].plot(kind=\"bar\", title=\"MSE for m_of_X\")\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- **Coefficient Values**: The coefficients for the `FLAML Manual Tuned` and `FLAML API Tuned` models are quite similar, with the API-tuned model having a slightly higher coefficient. Both are lower compared to the `AutoML Untuned` and `Dummy` models.\n",
    "- **Untuned AutoML Models**: The `AutoML Untuned` models yield a higher coefficient compared to the manually tuned FLAML models, indicating that the automated process of model tuning in AutoML may have overestimated the effect. The `Dummy` model has the highest coefficient, suggesting it could be overfitting or has a higher baseline value.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- The **FLAML Manual Tuned** and **FLAML API Tuned** models provide similar results with coefficients close to 0.5, suggesting robust performance within their tuned configurations.\n",
    "- The **AutoML Untuned** models offer higher coefficient values, indicating that even though they are untuned, they still provide a noticeable increase in coefficient compared to the tuned FLAML models.\n",
    "- The **Dummy** model, having the highest coefficient, shows the largest discrepancy. This reflects the fact, that the learner is not actually learning any meaningful relationship between the features and the outcome/treatment variable. \n",
    "\n",
    "Overall, the manually tuned FLAML models and the API-tuned FLAML models show good alignment with the expectations, while the untuned and dummy models present larger coefficients which may suggest the need for further tuning or validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
