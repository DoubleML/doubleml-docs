{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import fetch_401K\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "colors = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('whitegrid', {'axes.spines.top': False,\n",
    "                            'axes.spines.bottom': False,\n",
    "                            'axes.spines.left': False,\n",
    "                            'axes.spines.right': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_401K(return_type='DataFrame')\n",
    "#data['inc'] = data['inc']/1000 # income in 1000 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['e401'].value_counts().plot(kind='bar', color=colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['p401'].value_counts().plot(kind='bar', color=colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data, x=\"net_tfa\", hue=\"e401\", col=\"e401\",\n",
    "            kind=\"kde\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['e401', 'net_tfa']].groupby('e401').mean().diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['p401', 'net_tfa']].groupby('p401').mean().diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DoubleMLData object\n",
    "data_dml = dml.DoubleMLData(data, y_col='net_tfa', d_cols='e401',\n",
    "                            x_cols=['age', 'inc', 'educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear models (like lasso), we construct a dataframe with interactions and transformations\n",
    "features = data.copy()[['marr', 'twoearn', 'db', 'pira', 'hown']]\n",
    "\n",
    "poly_dict = {'age': 2,\n",
    "             'inc': 2,\n",
    "             'educ': 2,\n",
    "             'fsize': 2}\n",
    "for key, degree in poly_dict.items():\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    data_transf = poly.fit_transform(data[[key]])\n",
    "    x_cols = poly.get_feature_names([key])\n",
    "    data_transf = pd.DataFrame(data_transf, columns=x_cols)\n",
    "    \n",
    "    features = pd.concat((features, data_transf),\n",
    "                          axis=1, sort=False)\n",
    "\n",
    "model_data = pd.concat((data.copy()[['net_tfa', 'e401']], features.copy()),\n",
    "                        axis=1, sort=False)\n",
    "\n",
    "data_dml_flex = dml.DoubleMLData(model_data, y_col='net_tfa', d_cols='e401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dml_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-fraud",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estimate the ATE in the basic model with lasso\n",
    "Cs = 0.0001*np.logspace(0, 4, 10)\n",
    "\n",
    "lasso = make_pipeline(StandardScaler(), LassoCV(cv=5, max_iter=10000))\n",
    "lasso_class = make_pipeline(StandardScaler(),\n",
    "                            LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear',\n",
    "                                                 Cs = Cs, max_iter=1000))\n",
    "\n",
    "np.random.seed(123)\n",
    "# Initialize DoubleMLPLR model\n",
    "dml_plr_lasso = dml.DoubleMLPLR(data_dml,\n",
    "                                ml_g = lasso,\n",
    "                                ml_m = lasso_class,\n",
    "                                n_folds = 3)\n",
    "\n",
    "dml_plr_lasso.fit(store_predictions=True)\n",
    "dml_plr_lasso.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the ATE in the flexible model with lasso\n",
    "\n",
    "np.random.seed(123)\n",
    "# Initialize DoubleMLPLR model\n",
    "dml_plr_lasso = dml.DoubleMLPLR(data_dml_flex,\n",
    "                                ml_g = lasso,\n",
    "                                ml_m = lasso_class,\n",
    "                                n_folds = 3)\n",
    "\n",
    "dml_plr_lasso.fit(store_predictions=True)\n",
    "lasso_summary = dml_plr_lasso.summary\n",
    "\n",
    "lasso_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "randomForest = RandomForestRegressor(\n",
    "    n_estimators=500, max_depth=7, max_features=3, min_samples_leaf=3)\n",
    "randomForest_class = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=5, max_features=4, min_samples_leaf=7)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_plr_forest = dml.DoubleMLPLR(data_dml,\n",
    "                                 ml_g = randomForest,\n",
    "                                 ml_m = randomForest_class,\n",
    "                                 n_folds = 3)\n",
    "dml_plr_forest.fit(store_predictions=True)\n",
    "forest_summary = dml_plr_forest.summary\n",
    "\n",
    "forest_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trees\n",
    "trees = DecisionTreeRegressor(\n",
    "    max_depth=30, ccp_alpha=0.0047, min_samples_split=203, min_samples_leaf=67)\n",
    "trees_class = DecisionTreeClassifier(\n",
    "    max_depth=30, ccp_alpha=0.0042, min_samples_split=104, min_samples_leaf=34)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_plr_tree = dml.DoubleMLPLR(data_dml,\n",
    "                               ml_g = trees,\n",
    "                               ml_m = trees_class,\n",
    "                               n_folds = 3)\n",
    "dml_plr_tree.fit(store_predictions=True)\n",
    "tree_summary = dml_plr_tree.summary\n",
    "\n",
    "tree_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting\n",
    "boost = XGBRegressor(n_jobs=1, objective = \"reg:squarederror\",\n",
    "                     eta=0.1, n_estimators=35)\n",
    "boost_class = XGBClassifier(use_label_encoder=False, n_jobs=1,\n",
    "                            objective = \"binary:logistic\", eval_metric = \"logloss\",\n",
    "                            eta=0.1, n_estimators=34)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_plr_boost = dml.DoubleMLPLR(data_dml,\n",
    "                                ml_g = boost,\n",
    "                                ml_m = boost_class,\n",
    "                                n_folds = 3)\n",
    "dml_plr_boost.fit(store_predictions=True)\n",
    "boost_summary = dml_plr_boost.summary\n",
    "\n",
    "boost_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plr_summary = pd.concat((lasso_summary, forest_summary, tree_summary, boost_summary))\n",
    "plr_summary.index = ['lasso', 'forest', 'tree', 'xgboost']\n",
    "plr_summary[['coef', '2.5 %', '97.5 %']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.full((2, plr_summary.shape[0]), np.nan)\n",
    "errors[0, :] = plr_summary['coef'] - plr_summary['2.5 %']\n",
    "errors[1, :] = plr_summary['97.5 %'] - plr_summary['coef']\n",
    "plt.errorbar(plr_summary.index, plr_summary.coef, fmt='o', yerr=errors);\n",
    "plt.ylim([0, 12500]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "lasso = make_pipeline(StandardScaler(), LassoCV(cv=5, max_iter=20000))\n",
    "\n",
    "# Initialize DoubleMLIRM model\n",
    "dml_irm_lasso = dml.DoubleMLIRM(data_dml_flex,\n",
    "                          ml_g = lasso,\n",
    "                          ml_m = lasso_class,\n",
    "                          trimming_threshold = 0.01,\n",
    "                          n_folds = 3)\n",
    "dml_irm_lasso.fit(store_predictions=True) \n",
    "lasso_summary = dml_irm_lasso.summary\n",
    "\n",
    "lasso_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "randomForest = RandomForestRegressor(n_estimators=500)\n",
    "randomForest_class = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_irm_forest = dml.DoubleMLIRM(data_dml,\n",
    "                                 ml_g = randomForest,\n",
    "                                 ml_m = randomForest_class,\n",
    "                                 trimming_threshold = 0.01,\n",
    "                                 n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_irm_forest.set_ml_nuisance_params('ml_g0', 'e401', {\n",
    "    'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 7})\n",
    "dml_irm_forest.set_ml_nuisance_params('ml_g1', 'e401', {\n",
    "    'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 5})\n",
    "dml_irm_forest.set_ml_nuisance_params('ml_m', 'e401', {\n",
    "    'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 6})\n",
    "\n",
    "dml_irm_forest.fit(store_predictions=True) \n",
    "forest_summary = dml_irm_forest.summary\n",
    "\n",
    "forest_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trees\n",
    "trees = DecisionTreeRegressor(max_depth=30)\n",
    "trees_class = DecisionTreeClassifier(max_depth=30)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_irm_tree = dml.DoubleMLIRM(data_dml,\n",
    "                          ml_g = trees,\n",
    "                          ml_m = trees_class,\n",
    "                          trimming_threshold = 0.01,\n",
    "                          n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_irm_tree.set_ml_nuisance_params('ml_g0', 'e401', {\n",
    "    'ccp_alpha': 0.0016, 'min_samples_split': 74, 'min_samples_leaf': 24})\n",
    "dml_irm_tree.set_ml_nuisance_params('ml_g1', 'e401', {\n",
    "    'ccp_alpha': 0.0018, 'min_samples_split': 70, 'min_samples_leaf': 23})\n",
    "dml_irm_tree.set_ml_nuisance_params('ml_m', 'e401', {\n",
    "    'ccp_alpha': 0.0028, 'min_samples_split': 167, 'min_samples_leaf': 55})\n",
    "\n",
    "dml_irm_tree.fit(store_predictions=True)\n",
    "tree_summary = dml_irm_tree.summary\n",
    "\n",
    "tree_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting\n",
    "boost = XGBRegressor(n_jobs=1, objective = \"reg:squarederror\")\n",
    "boost_class = XGBClassifier(use_label_encoder=False, n_jobs=1,\n",
    "                            objective = \"binary:logistic\", eval_metric = \"logloss\")\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_irm_boost = dml.DoubleMLIRM(data_dml,\n",
    "                                ml_g = boost,\n",
    "                                ml_m = boost_class,\n",
    "                                trimming_threshold = 0.01,\n",
    "                                n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_irm_boost.set_ml_nuisance_params('ml_g0', 'e401', {\n",
    "    'eta': 0.1, 'n_estimators': 8})\n",
    "dml_irm_boost.set_ml_nuisance_params('ml_g1', 'e401', {\n",
    "    'eta': 0.1, 'n_estimators': 29})\n",
    "dml_irm_boost.set_ml_nuisance_params('ml_m', 'e401', {\n",
    "    'eta': 0.1, 'n_estimators': 23})\n",
    "\n",
    "dml_irm_boost.fit(store_predictions=True)\n",
    "boost_summary = dml_irm_boost.summary\n",
    "\n",
    "boost_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "irm_summary = pd.concat((lasso_summary, forest_summary, tree_summary, boost_summary))\n",
    "irm_summary.index = ['lasso', 'forest', 'tree', 'xgboost']\n",
    "irm_summary[['coef', '2.5 %', '97.5 %']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.full((2, irm_summary.shape[0]), np.nan)\n",
    "errors[0, :] = irm_summary['coef'] - irm_summary['2.5 %']\n",
    "errors[1, :] = irm_summary['97.5 %'] - irm_summary['coef']\n",
    "plt.errorbar(irm_summary.index, irm_summary.coef, fmt='o', yerr=errors);\n",
    "plt.ylim([0, 12500]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DoubleMLData object\n",
    "data_dml_iv = dml.DoubleMLData(data, y_col='net_tfa', d_cols='p401', z_cols='e401',\n",
    "                               x_cols=['age', 'inc', 'educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown'])\n",
    "\n",
    "model_data = pd.concat((data.copy()[['net_tfa', 'e401', 'p401']], features.copy()),\n",
    "                        axis=1, sort=False)\n",
    "\n",
    "data_dml_iv_flex = dml.DoubleMLData(model_data, y_col='net_tfa', d_cols='p401', z_cols='e401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "lasso = make_pipeline(StandardScaler(), LassoCV(cv=5, max_iter=20000))\n",
    "\n",
    "# Initialize DoubleMLIRM model\n",
    "dml_iivm_lasso = dml.DoubleMLIIVM(data_dml_iv_flex,\n",
    "                                  ml_g = lasso,\n",
    "                                  ml_m = lasso_class,\n",
    "                                  ml_r = lasso_class,\n",
    "                                  subgroups = {'always_takers': False,\n",
    "                                             'never_takers': True},\n",
    "                                  trimming_threshold = 0.01,\n",
    "                                  n_folds = 3)\n",
    "dml_iivm_lasso.fit(store_predictions=True)\n",
    "lasso_summary = dml_iivm_lasso.summary\n",
    "\n",
    "lasso_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "randomForest = RandomForestRegressor(n_estimators=500)\n",
    "randomForest_class = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_iivm_forest = dml.DoubleMLIIVM(data_dml_iv,\n",
    "                                   ml_g = randomForest,\n",
    "                                   ml_m = randomForest_class,\n",
    "                                   ml_r = randomForest_class,\n",
    "                                   subgroups = {'always_takers': False,\n",
    "                                                'never_takers': True},\n",
    "                                   trimming_threshold = 0.01,\n",
    "                                   n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_iivm_forest.set_ml_nuisance_params('ml_g0', 'p401', {\n",
    "    'max_depth': 6, 'max_features': 4, 'min_samples_leaf': 7})\n",
    "dml_iivm_forest.set_ml_nuisance_params('ml_g1', 'p401', {\n",
    "    'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 5})\n",
    "dml_iivm_forest.set_ml_nuisance_params('ml_m', 'p401', {\n",
    "    'max_depth': 6, 'max_features': 3, 'min_samples_leaf': 6})\n",
    "dml_iivm_forest.set_ml_nuisance_params('ml_r1', 'p401', {\n",
    "    'max_depth': 4, 'max_features': 7, 'min_samples_leaf': 6})\n",
    "\n",
    "dml_iivm_forest.fit(store_predictions=True) \n",
    "forest_summary = dml_iivm_forest.summary\n",
    "\n",
    "forest_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trees\n",
    "trees = DecisionTreeRegressor(max_depth=30)\n",
    "trees_class = DecisionTreeClassifier(max_depth=30)\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_iivm_tree = dml.DoubleMLIIVM(data_dml_iv,\n",
    "                                 ml_g = trees,\n",
    "                                 ml_m = trees_class,\n",
    "                                 ml_r = trees_class,\n",
    "                                 subgroups = {'always_takers': False,\n",
    "                                              'never_takers': True},\n",
    "                                 trimming_threshold = 0.01,\n",
    "                                 n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_iivm_tree.set_ml_nuisance_params('ml_g0', 'p401', {\n",
    "    'ccp_alpha': 0.0016, 'min_samples_split': 74, 'min_samples_leaf': 24})\n",
    "dml_iivm_tree.set_ml_nuisance_params('ml_g1', 'p401', {\n",
    "    'ccp_alpha': 0.0018, 'min_samples_split': 70, 'min_samples_leaf': 23})\n",
    "dml_iivm_tree.set_ml_nuisance_params('ml_m', 'p401', {\n",
    "    'ccp_alpha': 0.0028, 'min_samples_split': 167, 'min_samples_leaf': 55})\n",
    "dml_iivm_tree.set_ml_nuisance_params('ml_r1', 'p401', {\n",
    "    'ccp_alpha': 0.0576, 'min_samples_split': 55, 'min_samples_leaf': 18})\n",
    "\n",
    "dml_iivm_tree.fit(store_predictions=True)\n",
    "tree_summary = dml_iivm_tree.summary\n",
    "\n",
    "tree_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting\n",
    "boost = XGBRegressor(n_jobs=1, objective = \"reg:squarederror\")\n",
    "boost_class = XGBClassifier(use_label_encoder=False, n_jobs=1,\n",
    "                            objective = \"binary:logistic\", eval_metric = \"logloss\")\n",
    "\n",
    "np.random.seed(123)\n",
    "dml_iivm_boost = dml.DoubleMLIIVM(data_dml_iv,\n",
    "                                  ml_g = boost,\n",
    "                                  ml_m = boost_class,\n",
    "                                  ml_r = boost_class,\n",
    "                                  subgroups = {'always_takers': False,\n",
    "                                               'never_takers': True},\n",
    "                                  trimming_threshold = 0.01,\n",
    "                                  n_folds = 3)\n",
    "\n",
    "# Set nuisance-part specific parameters\n",
    "dml_iivm_boost.set_ml_nuisance_params('ml_g0', 'p401', {\n",
    "    'eta': 0.1, 'n_estimators': 9})\n",
    "dml_iivm_boost.set_ml_nuisance_params('ml_g1', 'p401', {\n",
    "    'eta': 0.1, 'n_estimators': 33})\n",
    "dml_iivm_boost.set_ml_nuisance_params('ml_m', 'p401', {\n",
    "    'eta': 0.1, 'n_estimators': 12})\n",
    "dml_iivm_boost.set_ml_nuisance_params('ml_r1', 'p401', {\n",
    "    'eta': 0.1, 'n_estimators': 25})\n",
    "\n",
    "dml_iivm_boost.fit(store_predictions=True)\n",
    "boost_summary = dml_iivm_boost.summary\n",
    "\n",
    "boost_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "iivm_summary = pd.concat((lasso_summary, forest_summary, tree_summary, boost_summary))\n",
    "iivm_summary.index = ['lasso', 'forest', 'tree', 'xgboost']\n",
    "iivm_summary[['coef', '2.5 %', '97.5 %']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.full((2, iivm_summary.shape[0]), np.nan)\n",
    "errors[0, :] = iivm_summary['coef'] - iivm_summary['2.5 %']\n",
    "errors[1, :] = iivm_summary['97.5 %'] - iivm_summary['coef']\n",
    "plt.errorbar(iivm_summary.index, iivm_summary.coef, fmt='o', yerr=errors);\n",
    "plt.ylim([0, 16500]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
