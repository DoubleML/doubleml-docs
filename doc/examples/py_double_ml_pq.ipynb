{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Python: Potential Quantiles and Quantile Treatment Effects\n",
    "In this example, we illustrate how the [DoubleML](https://docs.doubleml.org/stable/index.html) package can be used to estimate (local) potential quantiles and (local) quantile treatment effects. The estimation is based on [Kallus  et al. (2019)](https://arxiv.org/abs/1912.12945)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Quantiles (PQs)\n",
    "\n",
    "At first, we will start with the estimation of the quantiles of the potential outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data\n",
    "We define a data generating process to create synthetic data to compare the estimates to the true effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "import multiprocessing\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data is generated as a location-scale model with\n",
    "\n",
    "$$Y_i = \\text{loc}(D_i,X_i) + \\text{scale}(D_i,X_i)\\cdot\\varepsilon_i,$$\n",
    "\n",
    "where $X_i\\sim\\mathcal{U}[-1,1]^{p}$ and $\\varepsilon_i \\sim \\mathcal{N}(0,1)$.\n",
    "Further, the location and scale are determined according to the following functions\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{loc}(d,x) &:= 0.5d + 2dx_5 + 2\\cdot 1\\{x_2 > 0.1\\} - 1.7\\cdot 1\\{x_1x_3 > 0\\} - 3x_4 \\\\\n",
    "\\text{scale}(d,x) &:= \\sqrt{0.5d + 0.3dx_1 + 2},\n",
    "\\end{aligned}$$\n",
    "\n",
    "and the treatment takes the following form\n",
    "\n",
    "$$D_i = 1_{\\{(X_2 - X_4 + 1.5\\cdot 1\\{x_1 > 0\\} + \\epsilon_i > 0)\\}}$$\n",
    "\n",
    "with $\\epsilon_i \\sim \\mathcal{N}(0,1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_loc(D, X):\n",
    "  loc = 0.5*D + 2*D*X[:,4] + 2.0*(X[:,1] > 0.1) - 1.7*(X[:,0] * X[:,2] > 0) - 3*X[:,3]\n",
    "  return loc\n",
    "\n",
    "def f_scale(D, X):\n",
    "  scale = np.sqrt(0.5*D + 0.3*D*X[:,1] + 2)\n",
    "  return scale\n",
    "\n",
    "def dgp(n=200, p=5):\n",
    "    X = np.random.uniform(-1,1,size=[n,p])\n",
    "    D = ((X[:,1 ] - X[:,3] + 1.5*(X[:,0] > 0) + np.random.normal(size=n)) > 0)*1.0\n",
    "    epsilon = np.random.normal(size=n)\n",
    "\n",
    "    Y = f_loc(D, X) + f_scale(D, X)*epsilon\n",
    "\n",
    "    return Y, X, D, epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can calculate the true potential quantile analytically or through simulations. Here, we will just approximate the true potential quantile for a range of quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tau_vec = np.arange(0.1,0.95,0.05)\n",
    "n_true = int(10e+6)\n",
    "\n",
    "_, X_true, _, epsilon_true = dgp(n=n_true)\n",
    "D1 = np.ones(n_true)\n",
    "D0 = np.zeros(n_true)\n",
    "\n",
    "Y1 = f_loc(D1, X_true) + f_scale(D1, X_true)*epsilon_true\n",
    "Y0 = f_loc(D0, X_true) + f_scale(D0, X_true)*epsilon_true\n",
    "\n",
    "Y1_quant = np.quantile(Y1, q=tau_vec)\n",
    "Y0_quant = np.quantile(Y0, q=tau_vec)\n",
    "\n",
    "print(f'Potential Quantile Y(0): {Y0_quant}')\n",
    "print(f'Potential Quantile Y(1): {Y1_quant}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let us generate $n=5000$ observations and convert them to a [DoubleMLData](https://docs.doubleml.org/stable/api/generated/doubleml.DoubleMLData.html) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 5000\n",
    "np.random.seed(42)\n",
    "Y, X, D, _ = dgp(n=n)\n",
    "obj_dml_data = dml.DoubleMLData.from_arrays(X, Y, D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Potential Quantile Estimation\n",
    "Next, we can initialize our two machine learning algorithms to train the different nuisance elements. Then we can initialize the `DoubleMLPQ` objects and call `fit()` to estimate the relevant parameters. To obtain confidence intervals, we can use the `confint()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_m = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "ml_g = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "\n",
    "PQ_0 = np.full((len(tau_vec)), np.nan)\n",
    "PQ_1 = np.full((len(tau_vec)), np.nan)\n",
    "\n",
    "ci_PQ_0 = np.full((len(tau_vec),2), np.nan)\n",
    "ci_PQ_1 = np.full((len(tau_vec),2), np.nan)\n",
    "\n",
    "for idx_tau, tau in enumerate(tau_vec):\n",
    "    print(f'Quantile: {tau}')\n",
    "    dml_PQ_0 = dml.DoubleMLPQ(obj_dml_data,\n",
    "                              ml_g, ml_m,\n",
    "                              quantile=tau,\n",
    "                              treatment=0,\n",
    "                              n_folds=5)\n",
    "    dml_PQ_1 = dml.DoubleMLPQ(obj_dml_data,\n",
    "                              ml_g, ml_m,\n",
    "                              quantile=tau,\n",
    "                              treatment=1,\n",
    "                              n_folds=5)\n",
    "\n",
    "    dml_PQ_0.fit()\n",
    "    dml_PQ_1.fit()\n",
    "\n",
    "    ci_PQ_0[idx_tau, :] = dml_PQ_0.confint(level=0.95).to_numpy()\n",
    "    ci_PQ_1[idx_tau, :] = dml_PQ_1.confint(level=0.95).to_numpy()\n",
    "\n",
    "    PQ_0[idx_tau] = dml_PQ_0.coef\n",
    "    PQ_1[idx_tau] = dml_PQ_1.coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, let us take a look at the estimated quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {\"Quantile\": tau_vec, \"Y(0)\": Y0_quant, \"Y(1)\": Y1_quant,\n",
    "        \"DML Y(0)\": PQ_0, \"DML Y(1)\": PQ_1,\n",
    "        \"DML Y(0) lower\": ci_PQ_0[:, 0], \"DML Y(0) upper\": ci_PQ_0[:, 1],\n",
    "        \"DML Y(1) lower\": ci_PQ_1[:, 0], \"DML Y(1) upper\": ci_PQ_1[:, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, (ax1, ax2) = plt.subplots(1 ,2)\n",
    "ax1.grid(); ax2.grid()\n",
    "\n",
    "ax1.plot(df['Quantile'],df['DML Y(0)'], color='violet', label='Estimated Quantile Y(0)')\n",
    "ax1.plot(df['Quantile'],df['Y(0)'], color='green', label='True Quantile Y(0)')\n",
    "ax1.fill_between(df['Quantile'], df['DML Y(0) lower'], df['DML Y(0) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(-3, 4)\n",
    "\n",
    "ax2.plot(df['Quantile'],df['DML Y(1)'], color='violet', label='Estimated Quantile Y(1)')\n",
    "ax2.plot(df['Quantile'],df['Y(1)'], color='green', label='True Quantile Y(1)')\n",
    "ax2.fill_between(df['Quantile'], df['DML Y(1) lower'], df['DML Y(1) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(-3, 4)\n",
    "\n",
    "fig.suptitle('Potential Quantiles', fontsize=16)\n",
    "fig.supxlabel('Quantile')\n",
    "_ = fig.supylabel('Potential Quantile and 95%-CI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Quantile Treatment Effects (QTEs)\n",
    "In most cases, we want to evaluate the quantile treatment effect as the difference between potential quantiles.\n",
    "Here, different quantiles can be estimated in parallel with `n_jobs_models`.\n",
    "\n",
    "To estimate the quantile treatment effect, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "cores_used = np.min([5, n_cores - 1])\n",
    "print(f\"Number of Cores used: {cores_used}\")\n",
    "\n",
    "dml_QTE = dml.DoubleMLQTE(obj_dml_data,\n",
    "                          ml_g,\n",
    "                          ml_m,\n",
    "                          quantiles=tau_vec,\n",
    "                          n_folds=5)\n",
    "dml_QTE.fit(n_jobs_models=cores_used)\n",
    "print(dml_QTE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As for other ``dml`` objects, we can use ``bootstrap()`` and ``confint()`` methods to generate jointly valid confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ci_QTE = dml_QTE.confint(level=0.95, joint=False)\n",
    "\n",
    "dml_QTE.bootstrap(n_rep_boot=2000)\n",
    "ci_joint_QTE = dml_QTE.confint(level=0.95, joint=True)\n",
    "ci_joint_QTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As before, let us take a look at the estimated effects and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QTE = Y1_quant - Y0_quant\n",
    "data = {\"Quantile\": tau_vec, \"QTE\": QTE, \"DML QTE\": dml_QTE.coef,\n",
    "        \"DML QTE pointwise lower\": ci_QTE['2.5 %'], \"DML QTE pointwise upper\": ci_QTE['97.5 %'],\n",
    "        \"DML QTE joint lower\": ci_joint_QTE['2.5 %'], \"DML QTE joint upper\": ci_joint_QTE['97.5 %']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(df['Quantile'],df['DML QTE'], color='violet', label='Estimated QTE')\n",
    "ax.plot(df['Quantile'],df['QTE'], color='green', label='True QTE')\n",
    "ax.fill_between(df['Quantile'], df['DML QTE pointwise lower'], df['DML QTE pointwise upper'], color='violet', alpha=.3, label='Pointwise Confidence Interval')\n",
    "ax.fill_between(df['Quantile'], df['DML QTE joint lower'], df['DML QTE joint upper'], color='violet', alpha=.2, label='Joint Confidence Interval')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Quantile Treatment Effects', fontsize=16)\n",
    "plt.xlabel('Quantile')\n",
    "_ = plt.ylabel('QTE and 95%-CI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Potential Quantiles (LPQs)\n",
    "\n",
    "Next, we will consider local potential quantiles and the corresponding local quantile treatment effects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We add a counfounder and an instrument to our data generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "import multiprocessing\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is generated as a location-scale model with confounding of the treatment $D_i$ and instrument $Z_i$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Y_i &= \\text{loc}\\left(D_i,X_i, X^{(conf)}_i\\right) + \\text{scale}\\left(D_i,X_i, X^{(conf)}_i\\right)\\cdot\\varepsilon_i,\\\\\n",
    "D_i &=1\\{0.5Z_i -0.3X_{i,1}+0.7X^{(conf)}_i + \\eta_i > 0\\},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $X_i\\sim\\mathcal{U}[-1,1]^{p}$, $X^{(conf)}_i \\sim\\mathcal{U}[-1,1]$, $Z_i\\sim \\mathcal{B}(1,1/2)$, $\\varepsilon_i \\sim \\mathcal{N}(0,1)$ and $\\eta_i \\sim \\mathcal{N}(0,1)$.\n",
    "Further, the location and scale are determined according to the following functions\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{loc}(d,x) &:= 0.5d + 2dx_5 + 2\\cdot 1\\{x_2 > 0.1\\} - 1.7\\cdot 1\\{x_1x_3 > 0\\} - 3x_4 - 2x^{(conf)}\\\\\n",
    "\\text{scale}(d,x, x^{(conf)}) &:= \\sqrt{0.5d + 3dx_1 + 0.4x^{(conf)} + 2}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loc(D, X, X_conf):\n",
    "  loc = 0.5*D + 2*D*X[:,4] + 2.0*(X[:,1] > 0.1) - 1.7*(X[:,0] * X[:,2] > 0) - 3*X[:,3] - 2*X_conf[:, 0]\n",
    "  return loc\n",
    "\n",
    "def f_scale(D, X, X_conf):\n",
    "  scale = np.sqrt(0.5*D + 3*D*X[:, 0] + 0.4*X_conf[:, 0] + 2)\n",
    "  return scale\n",
    "\n",
    "def generate_treatment(Z, X, X_conf):\n",
    "    eta = np.random.normal(size=len(Z))\n",
    "    d = ((0.5*Z -0.3*X[:, 0] + 0.7*X_conf[:, 0] + eta) > 0)*1.0\n",
    "    return d\n",
    "\n",
    "def dgp(n=200, p=5):\n",
    "    X = np.random.uniform(0, 1, size=[n,p])\n",
    "    X_conf = np.random.uniform(-1, 1, size=[n,1])\n",
    "    Z = np.random.binomial(1, p=0.5, size=n)\n",
    "    D = generate_treatment(Z, X, X_conf)\n",
    "    epsilon = np.random.normal(size=n)\n",
    "\n",
    "    Y = f_loc(D, X, X_conf) + f_scale(D, X, X_conf)*epsilon\n",
    "\n",
    "    return Y, X, D, Z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will just simulate the true quantile for a range of quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_vec = np.arange(0.1,0.95,0.05)\n",
    "n_true = int(10e+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=5\n",
    "X_true = np.random.uniform(0, 1, size=[n_true,p])\n",
    "X_conf_true = np.random.uniform(-1, 1, size=[n_true,1])\n",
    "Z_true = np.random.binomial(1, p=0.5, size=n_true)\n",
    "eta_true = np.random.normal(size=n_true)\n",
    "D1_true = generate_treatment(np.ones_like(Z_true), X_true, X_conf_true)\n",
    "D0_true = generate_treatment(np.zeros_like(Z_true), X_true, X_conf_true)\n",
    "epsilon_true = np.random.normal(size=n_true)\n",
    "\n",
    "compliers = (D1_true == 1) * (D0_true == 0)\n",
    "print(f'Compliance probability: {str(compliers.mean())}')\n",
    "n_compliers = compliers.sum()\n",
    "Y1 = f_loc(np.ones(n_compliers), X_true[compliers, :], X_conf_true[compliers, :]) + f_scale(np.ones(n_compliers), X_true[compliers, :], X_conf_true[compliers, :])*epsilon_true[compliers]\n",
    "Y0 = f_loc(np.zeros(n_compliers), X_true[compliers, :], X_conf_true[compliers, :]) + f_scale(np.zeros(n_compliers), X_true[compliers, :], X_conf_true[compliers, :])*epsilon_true[compliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0_quant = np.quantile(Y0, q=tau_vec)\n",
    "Y1_quant = np.quantile(Y1, q=tau_vec)\n",
    "\n",
    "print(f'Local Potential Quantile Y(0): {Y0_quant}')\n",
    "print(f'Local Potential Quantile Y(1): {Y1_quant}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate $n=10000$ observations and convert them to a [DoubleMLData](https://docs.doubleml.org/stable/api/generated/doubleml.DoubleMLData.html) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "np.random.seed(42)\n",
    "Y, X, D, Z = dgp(n=n,p=p)\n",
    "obj_dml_data = dml.DoubleMLData.from_arrays(X, Y, D, Z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Potential Quantile Estimation\n",
    "Next, we can initialize our two machine learning algorithms to train the different nuisance elements. As above, we can initialize the `DoubleMLLPQ` objects and call `fit()` to estimate the relevant parameters. To obtain confidence intervals, we can use the `confint()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_m = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "ml_g = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=10)\n",
    "\n",
    "LPQ_0 = np.full((len(tau_vec)), np.nan)\n",
    "LPQ_1 = np.full((len(tau_vec)), np.nan)\n",
    "\n",
    "ci_LPQ_0 = np.full((len(tau_vec),2), np.nan)\n",
    "ci_LPQ_1 = np.full((len(tau_vec),2), np.nan)\n",
    "\n",
    "for idx_tau, tau in enumerate(tau_vec):\n",
    "    print(f'Quantile: {tau}')\n",
    "    dml_LPQ_0 = dml.DoubleMLLPQ(obj_dml_data,\n",
    "                                ml_g,\n",
    "                                ml_m,\n",
    "                                score=\"LPQ\",\n",
    "                                treatment=0,\n",
    "                                quantile=tau,\n",
    "                                n_folds=5,\n",
    "                                trimming_threshold=0.05)\n",
    "    dml_LPQ_1 = dml.DoubleMLLPQ(obj_dml_data,\n",
    "                                ml_g,\n",
    "                                ml_m,\n",
    "                                score=\"LPQ\",\n",
    "                                treatment=1,\n",
    "                                quantile=tau,\n",
    "                                n_folds=5,\n",
    "                                trimming_threshold=0.05)\n",
    "\n",
    "    dml_LPQ_0.fit()\n",
    "    dml_LPQ_1.fit()\n",
    "\n",
    "    LPQ_0[idx_tau] = dml_LPQ_0.coef\n",
    "    LPQ_1[idx_tau] = dml_LPQ_1.coef\n",
    "\n",
    "    ci_LPQ_0[idx_tau, :] = dml_LPQ_0.confint(level=0.95).to_numpy()\n",
    "    ci_LPQ_1[idx_tau, :] = dml_LPQ_1.confint(level=0.95).to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us take a look at the estimated local quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Quantile\": tau_vec, \"Y(0)\": Y0_quant, \"Y(1)\": Y1_quant,\n",
    "        \"DML Y(0)\": LPQ_0, \"DML Y(1)\": LPQ_1,\n",
    "        \"DML Y(0) lower\": ci_LPQ_0[:, 0], \"DML Y(0) upper\": ci_LPQ_0[:, 1],\n",
    "        \"DML Y(1) lower\": ci_LPQ_1[:, 0], \"DML Y(1) upper\": ci_LPQ_1[:, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, (ax1, ax2) = plt.subplots(1 ,2)\n",
    "ax1.grid(); ax2.grid()\n",
    "\n",
    "ax1.plot(df['Quantile'],df['DML Y(0)'], color='violet', label='Estimated Local Quantile Y(0)')\n",
    "ax1.plot(df['Quantile'],df['Y(0)'], color='green', label='True Local Quantile Y(0)')\n",
    "ax1.fill_between(df['Quantile'], df['DML Y(0) lower'], df['DML Y(0) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(-3, 4)\n",
    "\n",
    "ax2.plot(df['Quantile'],df['DML Y(1)'], color='violet', label='Estimated Local Quantile Y(1)')\n",
    "ax2.plot(df['Quantile'],df['Y(1)'], color='green', label='True Local Quantile Y(1)')\n",
    "ax2.fill_between(df['Quantile'], df['DML Y(1) lower'], df['DML Y(1) upper'], color='violet', alpha=.3, label='Confidence Interval')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(-3, 4)\n",
    "\n",
    "fig.suptitle('Local Potential Quantiles', fontsize=16)\n",
    "fig.supxlabel('Quantile')\n",
    "_ = fig.supylabel('Local Potential Quantile and 95%-CI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Quantile Treatment Effects (LQTEs)\n",
    "As for quantile treatment effects, we often want to evaluate the (local) treatment effect.\n",
    "To estimate local quantile treatment effects, we can use the `DoubleMLQTE` object and specify `LPQ` as the score. \n",
    "\n",
    "As for quantile treatment effects, different quantiles can be estimated in parallel with `n_jobs_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "cores_used = np.min([5, n_cores - 1])\n",
    "print(f\"Number of Cores used: {cores_used}\")\n",
    "\n",
    "dml_LQTE = dml.DoubleMLQTE(obj_dml_data, \n",
    "                           ml_g=ml_g,\n",
    "                           ml_m=ml_m, \n",
    "                           quantiles=tau_vec, \n",
    "                           score='LPQ', \n",
    "                           n_folds=5)\n",
    "dml_LQTE.fit(n_jobs_models=cores_used)\n",
    "print(dml_LQTE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for other ``dml`` objects, we can use ``bootstrap()`` and ``confint()`` methods to generate jointly valid confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_LQTE = dml_LQTE.confint(level=0.95, joint=False)\n",
    "\n",
    "dml_LQTE.bootstrap(n_rep_boot=2000)\n",
    "ci_joint_LQTE = dml_LQTE.confint(level=0.95, joint=True)\n",
    "ci_joint_LQTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let us take a look at the estimated effects and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LQTE = Y1_quant - Y0_quant\n",
    "data = {\"Quantile\": tau_vec, \"LQTE\": LQTE, \"DML LQTE\": dml_LQTE.coef,\n",
    "        \"DML LQTE pointwise lower\": ci_LQTE['2.5 %'], \"DML LQTE pointwise upper\": ci_LQTE['97.5 %'],\n",
    "        \"DML LQTE joint lower\": ci_joint_LQTE['2.5 %'], \"DML LQTE joint upper\": ci_joint_LQTE['97.5 %']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10., 7.5\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(df['Quantile'],df['DML LQTE'], color='violet', label='Estimated LQTE')\n",
    "ax.plot(df['Quantile'],df['LQTE'], color='green', label='True LQTE')\n",
    "ax.fill_between(df['Quantile'], df['DML LQTE pointwise lower'], df['DML LQTE pointwise upper'], color='violet', alpha=.3, label='Pointwise Confidence Interval')\n",
    "ax.fill_between(df['Quantile'], df['DML LQTE joint lower'], df['DML LQTE joint upper'], color='violet', alpha=.2, label='Joint Confidence Interval')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Local Quantile Treatment Effects', fontsize=16)\n",
    "plt.xlabel('Quantile')\n",
    "_ = plt.ylabel('LQTE and 95%-CI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "04413e1efd13b5e2aaedccc5facec5686292d28983ef24fa021a12c73bd6369e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
