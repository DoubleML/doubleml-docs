{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: Confidence intervals for instrumental variables models that are robust to weak instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will show how to use the DoubleML package to obtain confidence sets for the treatment effects that are robust to weak instruments. Weak instruments are those that have a relatively weak correlation with the treatment. It is well known that in this case, standard methods to construct confidence intervals have poor properties and can have coverage much lower than the nominal value. We will assume that the reader of this notebook is already familiar with DoubleML and how it can be used to fit instrumental variable models.\n",
    "\n",
    "Throughout this example\n",
    "\n",
    "- Z is the instrument,\n",
    "- X is a vector of covariates,\n",
    "- D is treatment variable,\n",
    "- Y is the outcome.\n",
    "\n",
    "Next, we will generate two synthetic data sets, one where the instrument is weak and another where it is not. Then, we will compare the output of the standard way to compute confidence intervals using the DoubleMLIIVM class, with the confidence sets computed using the uniform_confset method from the same class. We will see that using the uniform_confset method is an easy way to ensure the results of an analysis are robust to weak instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import doubleml as dml\n",
    "\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e45c7",
   "metadata": {},
   "source": [
    "The following function generates data from an instrumental variables model. The true_effect argument is the estimand of interest, the true effect of the treatment on the outcome. The instrument_strength argument is a measure of the strength of the instrument. The higher it is, the stronger the correlation is between the instrument and the treatment. Notice that the instrument is fully randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82111204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weakiv_data(n_samples, true_effect, instrument_strength):\n",
    "    u = np.random.normal(0, 2, size=n_samples)\n",
    "    X = np.random.normal(0, 1, size=n_samples)\n",
    "    Z = np.random.binomial(1, 0.5, size=n_samples)\n",
    "    D = instrument_strength * Z + u \n",
    "    D = np.array(D > 0, dtype=int)\n",
    "    Y = true_effect * D + np.sign(u)\n",
    "    return pd.DataFrame({\"Y\": Y, \"Z\": Z, \"D\": D, \"X\": X})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c938fd8",
   "metadata": {},
   "source": [
    "We call the function two times to get two data sets, one where the instrument is weak, the other where the instrument is strong. In both cases the true effect is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a58c545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weak = generate_weakiv_data(5000, 1, 0.003)\n",
    "data_strong = generate_weakiv_data(5000, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the DoubleML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit the DoubleML model. We begin by preparing the two data sets into the DoubleMLData format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600b8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_data_strong = dml.DoubleMLData(\n",
    "    data_strong, y_col='Y', d_cols='D', \n",
    "    z_cols='Z', x_cols='X'\n",
    ")\n",
    "dml_data_weak = dml.DoubleMLData(\n",
    "    data_weak, y_col='Y', d_cols='D', \n",
    "    z_cols='Z', x_cols='X'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff957e",
   "metadata": {},
   "source": [
    "Next, we define the nuisance estimators we will use. We will use a linear regression model for g, and a logistic regression for r. We will assume that we know the true m function, as is the case in a controlled experiment, such as an AB test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962900bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueMFunction(LogisticRegression):\n",
    "    def predict(self, X):\n",
    "        return np.full(X.shape[0], 0.5)\n",
    "\n",
    "ml_g = LinearRegression()\n",
    "ml_m = TrueMFunction()\n",
    "ml_r = LogisticRegression(penalty=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd3370",
   "metadata": {},
   "source": [
    "Now, we fit the DoubleML model on the data set with a strong instrument and then print both the standard and robust results confidence sets. We see that the results are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549c98fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard confidence interval results\n",
      "       coef   std err         t         P>|t|    2.5 %    97.5 %\n",
      "D  0.951444  0.144382  6.589761  4.405342e-11  0.66846  1.234428\n",
      "Uniform confidence set results\n",
      "[(np.float64(0.6317710537372013), np.float64(1.206690551996729))]\n"
     ]
    }
   ],
   "source": [
    "dml_iivm_strong = dml.DoubleMLIIVM(dml_data_strong, ml_g, ml_m, ml_r)\n",
    "\n",
    "print(\"Standard confidence interval results\")\n",
    "print(dml_iivm_strong.fit().summary)\n",
    "print(\"Uniform confidence set results\")\n",
    "print(dml_iivm_strong.robust_confset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd61dd",
   "metadata": {},
   "source": [
    "We now repeat the process with the weak instruments data set. In this case, the standard method reports a confidence interval equal to [2.08, 3.46]. Thus, an analyst reading this would think that she can have high confidence that the true effect is roughly between 2 and 3.5. We know however that the true effect is equal to 1, and thus that the standard DoubleML estimator is badly biased in this case. On the other hand, the uniform confidence set method returns the whole real line as a confidence interval. This indicates that the data does not contain enough information to make any claims about the effect of the treatment of the outcome, because the instrument is too weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d98c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard confidence interval results\n",
      "       coef   std err         t     P>|t|     2.5 %    97.5 %\n",
      "D  2.210317  3.689771  0.599039  0.549147 -5.021502  9.442136\n",
      "Uniform confidence set results\n",
      "[(-inf, inf)]\n"
     ]
    }
   ],
   "source": [
    "ml_g = LinearRegression()\n",
    "ml_m = TrueMFunction()\n",
    "ml_r = LogisticRegression(penalty=None)\n",
    "dml_iivm_weak = dml.DoubleMLIIVM(dml_data_weak, ml_g, ml_m, ml_r)\n",
    "\n",
    "print(\"Standard confidence interval results\")\n",
    "print(dml_iivm_weak.fit().summary)\n",
    "print(\"Uniform confidence set results\")\n",
    "print(dml_iivm_weak.robust_confset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5629c5",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cbbcf",
   "metadata": {},
   "source": [
    "- Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., and Hansen, C. (2018). Double/debiased machine learning for\n",
    "treatment and structural parameters. The Econometrics Journal, 21(1):C1–C68.\n",
    "- Ma, Y. (2023). Identification-robust inference for the late with high-dimensional covariates. arXiv preprint arXiv:2302.09756.\n",
    "- Stock, J. H. and Wright, J. H. (2000). GMM with weak identification. Econometrica, 68(5):1055–1096.\n",
    "- Takatsu, K., Levis, A. W., Kennedy, E., Kelz, R., and Keele, L. (2023). Doubly robust machine learning for an instrumental\n",
    "variable study of surgical care for cholecystitis. arXiv preprint arXiv:2307.06269."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce927dd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
