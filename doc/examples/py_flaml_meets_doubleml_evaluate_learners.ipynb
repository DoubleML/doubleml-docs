import xgboost as xgb
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

from doubleml.datasets import make_plr_CCDDHNR2018
import doubleml as dml
from flaml import AutoML
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Set up visualization settings
sns.set()
colors = sns.color_palette()
plt.rcParams['figure.figsize'] = 10., 7.5
sns.set(font_scale=1.5)
sns.set_style('whitegrid', {
    'axes.spines.top': False,
    'axes.spines.bottom': False,
    'axes.spines.left': False,
    'axes.spines.right': False
})

# Generate synthetic data
data = make_plr_CCDDHNR2018(alpha=0.5, n_obs=1000, dim_x=50, return_type="DataFrame")

# Split data into flaml training and doubleml evaluation sets
data_flaml, data_dml = train_test_split(data, test_size=0.5)

# Initialize AutoML for outcome model (ml_l)
automl_l = AutoML()
settings_l = {
    "time_budget": 120,
    "metric": 'mse',
    "estimator_list": ['xgboost'],
    "task": 'regression',
}
automl_l.fit(X_train=data_flaml.drop(columns=["y", "d"]).values, y_train=data_flaml["y"].values, verbose=2, **settings_l)

# Check for Overfitting: Compare in-sample (train), out-of-sample (test) MSE
# ml_l
pres_ins_ml_l = automl_l.model.estimator.predict(data_flaml.drop(columns=["y", "d"]).values)
mse_ins_ml_l = mean_squared_error(data_flaml.y.values, pres_ins_ml_l)
pres_oos_ml_l = automl_l.model.estimator.predict(data_dml.drop(columns=["y", "d"]).values)
mse_oos_ml_l = mean_squared_error(data_dml.y.values, pres_oos_ml_l)

print("In-sample MSE (ml_l):", mse_ins_ml_l)
print("Out-of-sample MSE (ml_l):", mse_oos_ml_l)

# Initialize AutoML for treatment model (ml_m)
automl_m = AutoML()
settings_m = {
    "time_budget": 120,
    "metric": 'mse',
    "estimator_list": ['xgboost'],
    "task": 'regression',
}
automl_m.fit(X_train=data_flaml.drop(columns=["y", "d"]).values, y_train=data_flaml["d"].values, verbose=2, **settings_m)

# Check for Overfitting: Compare in-sample (train), out-of-sample (test) MSE
# ml_m
pres_ins_ml_m = automl_m.model.estimator.predict(data_flaml.drop(columns=["y", "d"]).values)
mse_ins_ml_m = mean_squared_error(data_flaml.d.values, pres_ins_ml_m)
pres_oos_ml_m = automl_m.model.estimator.predict(data_dml.drop(columns=["y", "d"]).values)
mse_oos_ml_m = mean_squared_error(data_dml.d.values, pres_oos_ml_m)

print("In-sample MSE (ml_m):", mse_ins_ml_m)
print("Out-of-sample MSE (ml_m):", mse_oos_ml_m)

# Create DoubleMLData object with the evaluation set
obj_dml_data = dml.DoubleMLData(data_dml, "y", "d")

# Initialize DoubleMLPLR with the trained models from flaml
# Here, we use the same estimator for ml_g and ml_l
obj_dml_plr = dml.DoubleMLPLR(obj_dml_data, ml_g=automl_l.model.estimator, ml_m=automl_m.model.estimator, ml_l=automl_l.model.estimator)

# Fit the DoubleMLPLR model
obj_dml_plr.fit()

# Evaluate learners using evaluate_learners() (MSE for all nuisance components)
mse_ml_l = obj_dml_plr.evaluate_learners()['ml_l'][0]
mse_ml_m = obj_dml_plr.evaluate_learners()['ml_m'][0]

# Print results
print(f"The MSE for outcome model (ml_l): {mse_ml_l:.3f}")
print(f"The MSE for treatment model (ml_m): {mse_ml_m:.3f}")
